import os
import csv
import pandas as pd
from typing import List, Dict
from collections import defaultdict
from Common.CEnum import KL_TYPE
from Chan import CChan


def extract_features_from_cbs_points(chan: CChan, lv: KL_TYPE) -> Dict[str, List[dict]]:
    """
    Extract features from all CBS_Points in the given level of the chan system.
    Returns a dictionary of feature lists, grouped by BS type (e.g., "1", "2", "2s").
    """
    bs_points = chan.kl_datas[lv].bs_point_lst.getSortedBspList()
    grouped_features = defaultdict(list)

    for bsp in bs_points:
        base_feat = {
            'index': bsp.klu.idx,
            'type': bsp.type2str(),
            'is_buy': bsp.is_buy,
            'divergence_rate': getattr(bsp, 'divergence_rate', None),
            'is_segbsp': getattr(bsp, 'is_segbsp', False),
            'timestamp': bsp.klu.time,
        }

        if bsp.features:
            extra_feat = bsp.features.to_dict()
            all_feat = {**base_feat, **extra_feat}
        else:
            all_feat = base_feat

        for t in bsp.type:
            grouped_features[t.value].append(all_feat)

    return grouped_features


def export_bs_feature_files_by_type(chan: CChan, lv: KL_TYPE, output_dir: str):
    """
    Export BS point features to multiple CSV files, grouped by BS type.
    Each file will be named like: `bs_features_type_<type>.csv`.
    """
    os.makedirs(output_dir, exist_ok=True)

    grouped = extract_features_from_cbs_points(chan, lv)

    if not grouped:
        print("No BS points found.")
        return

    for bs_type, features in grouped.items():
        if not features:
            continue

        all_fieldnames = set()
        for feat in features:
            all_fieldnames.update(feat.keys())
        fieldnames = sorted(all_fieldnames)

        filename = os.path.join(output_dir, f"bs_features_type_{bs_type}.csv")
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(features)

        print(f"[âœ“] Exported {len(features)} '{bs_type}' BS points to: {filename}")


def sanitize_row_key(chain_type: str, direction: str) -> str:
    """
    æ¸…æ´— chain_type å’Œ directionï¼Œç¡®ä¿æ²¡æœ‰éæ³•å­—ç¬¦ã€‚
    æ¯”å¦‚ '1p'>' -> '1p'
    """
    def clean(s):
        return str(s).strip(" '>\n\t\"")  # å»é™¤ç©ºæ ¼ã€å¼•å·ã€å°–æ‹¬å·ç­‰

    return f"{clean(chain_type)}_{clean(direction)}"

def extract_bsp_feature_row(bsp, bs_type, direction, chain_id, point_index):
    """å•ç‹¬æŠ½å‡ºä¸€ä¸ª BSP ç‚¹çš„ç‰¹å¾æå–é€»è¾‘"""
    row = {
        'chain_type': bs_type,
        'direction': direction,
        'chain_id': chain_id,
        'point_index': point_index,
        'klu_idx': bsp.klu.idx,
        'timestamp': bsp.klu.time,
        'klu_close': bsp.klu.close,
        'bsp_type': bsp.type2str(),
        'is_buy': bsp.is_buy,
        'is_segbsp': getattr(bsp, 'is_segbsp', False),
        'mature_rate': None,
        'is_mature': 0,
        'parent_idx': None,
    }

    if bsp.features:
        row.update(bsp.features.to_dict())

    return row

def extract_all_chain_features(chains_by_type: dict) -> list:
    all_rows = []
    chain_counter = 0

    type_to_amp_field = {
        '1': 'bsp1_bi_amp',
        '1p': 'bsp1_bi_amp',
        '2': 'bsp2_bi_amp',
        '2s': 'bsp2s_bi_amp',
        '3a': 'bsp3_bi_amp',
        '3b': 'bsp3_bi_amp',
    }

    for raw_key, bsp_list in chains_by_type.items():
        if not bsp_list:
            continue

        # Flatten if nested
        if isinstance(bsp_list[0], list):
            bsp_list = [bsp for sublist in bsp_list for bsp in sublist]

        try:
            direction_raw = raw_key.split("_")[-1].strip()
            bs_type_raw = raw_key.split(":")[-1].split(">")[0].strip(" '")
            key = sanitize_row_key(bs_type_raw, direction_raw)
        except Exception as e:
            print(f"[âš ] Cannot parse raw_key: {raw_key}, skipping. Error: {e}")
            continue

        if "_" not in key:
            continue

        bs_type, direction = key.split("_")

        # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œé¿å…ä¹±åº
        chain = sorted(bsp_list, key=lambda b: getattr(b.klu, "ts", float("inf")))

        # æ‰¾æ‰€æœ‰æˆç†Ÿç‚¹ç´¢å¼•
        mature_indices = []
        for i, bsp in enumerate(chain):
            features = bsp.features.to_dict() if bsp.features else {}
            if pd.notna(features.get("next_bi_return")):
                mature_indices.append(i)

        # æ’å…¥æœ€åä¸€ä¸ªå“¨å…µç‚¹ï¼ˆæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘ï¼‰
        segment_ends = mature_indices + [len(chain)]

        used_indices = set()

        for seg_idx in range(len(mature_indices)):
            start = 0 if seg_idx == 0 else mature_indices[seg_idx - 1] + 1
            end = segment_ends[seg_idx]

            mature_index = mature_indices[seg_idx]
            mature_bsp = chain[mature_index]
            mature_features = mature_bsp.features.to_dict() if mature_bsp.features else {}
            bsp_type = mature_bsp.type2str()
            amp_field = type_to_amp_field.get(bsp_type)

            if not amp_field:
                print(f"[âš ] Unknown bsp_type '{bsp_type}', skipping chain {key}")
                continue

            mature_amp = mature_features.get(amp_field)
            mature_klu_idx = getattr(mature_bsp.klu, "idx", None)

            if not mature_amp or mature_amp == 0:
                continue

            # ä¸º start ~ mature_index çš„ç‚¹åŠ æ ‡æ³¨
            for i in range(start, mature_index + 1):
                bsp = chain[i]
                features = bsp.features.to_dict() if bsp.features else {}
                row = extract_bsp_feature_row(
                    bsp, bs_type, direction, chain_id=chain_counter, point_index=i
                )

                if i < mature_index:
                    current_amp = features.get(amp_field)
                    if current_amp is not None:
                        row['mature_rate'] = round(min(current_amp / mature_amp, 1), 6)
                    row['parent_idx'] = mature_klu_idx
                    row['is_mature'] = 0
                elif i == mature_index:
                    row['mature_rate'] = 1
                    row['is_mature'] = 1
                    row['parent_idx'] = None

                used_indices.add(i)
                all_rows.append(row)

            chain_counter += 1

        # å‰©ä¸‹çš„æœ«å°¾æœªå½’å±åŒºåŸŸ
        for i, bsp in enumerate(chain):
            if i in used_indices:
                continue
            row = extract_bsp_feature_row(
                bsp, bs_type, direction, chain_id=None, point_index=i
            )
            row['mature_rate'] = None
            row['is_mature'] = 0
            row['parent_idx'] = None
            all_rows.append(row)

    print(f"[âœ“] Extracted {len(all_rows)} BS point features from all reconstructed chains.")
    return all_rows



def export_chain_features_by_type(chan: CChan, lv: KL_TYPE, output_dir: str):
    """
    å¯¼å‡º chan.bs_chain_tracker ä¸­æ‰€æœ‰é“¾æ¡çš„ç‰¹å¾ã€‚
    æ¯æ¡é“¾ä¸€ä»½ CSV æ–‡ä»¶ï¼Œæ–‡ä»¶ååŒ…å«é“¾ç±»å‹ã€æ–¹å‘ã€ç¼–å·ã€‚
    """
    os.makedirs(output_dir, exist_ok=True)

    if not hasattr(chan, "bs_chain_tracker"):
        print("[âŒ] No bs_chain_tracker found on chan.")
        return

    chains_by_type = chan.bs_chain_tracker.chains_by_type
    rows = extract_all_chain_features(chains_by_type)
    #rows = postprocess_maturity_features(rows)

    export_chains_from_flat_rows(rows, output_dir)

def export_chains_from_flat_rows(rows: list, output_dir: str):
    """
    ä»æ‰å¹³åŒ–çš„ rows ä¸­ï¼Œæ ¹æ® chain_type å’Œ direction åˆ†ç±»å¯¼å‡º CSVã€‚
    æ¯ç§ç±»å‹ï¼ˆå¦‚ 1p_buyï¼‰å¯¼å‡ºä¸€ä¸ªæ–‡ä»¶ã€‚
    """
    os.makedirs(output_dir, exist_ok=True)
    grouped = defaultdict(list)

    for row in rows:
        key = f"{row['chain_type']}_{row['direction']}"
        grouped[key].append(row)

    total_files = 0
    for key, group_rows in grouped.items():
        if not group_rows:
            continue
        path = os.path.join(output_dir, f"bs_chain_group_{key}.csv")
        all_fields = set()
        for row in group_rows:
            all_fields.update(row.keys())
        fieldnames = sorted(all_fields)
        with open(path, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(group_rows)
        print(f"[âœ“] Exported {len(group_rows)} rows to {path}")
        total_files += 1

    if total_files == 0:
        print("[âš ] No data exported. Check if input rows are empty.")

# def postprocess_maturity_features(rows: list) -> list:
#     """
#     æ ¹æ®æ¯ç§ BS ç‚¹ç±»å‹çš„ä¸“å±å¹…åº¦å­—æ®µï¼ˆå¦‚ bsp2_bi_ampï¼‰æ¥è®¡ç®— mature_rateã€‚
#     åˆ¤æ–­æ¡ä»¶æ˜¯ next_bi_return éç©ºçš„ç‚¹å³ä¸ºæˆç†Ÿç‚¹ã€‚
#     """
#     from collections import defaultdict
#     import pandas as pd

#     # ä¸åŒç±»å‹ä½¿ç”¨ä¸åŒçš„å¹…åº¦å­—æ®µ
#     type_to_amp_field = {
#         '1': 'bsp1_bi_amp',
#         '1p': 'bsp1_bi_amp',
#         '2': 'bsp2_bi_amp',
#         '2s': 'bsp2s_bi_amp',
#         '3a': 'bsp3_bi_amp',
#         '3b': 'bsp3_bi_amp',
#     }

#     grouped = defaultdict(list)
#     for row in rows:
#         key = (row['chain_type'], row['direction'], row['chain_id'])
#         grouped[key].append(row)


#     for key, chain_rows in grouped.items():
#         chain_rows.sort(key=lambda x: x['klu_idx'])

#         # æ‰¾ç¬¬ä¸€ä¸ªæˆç†Ÿç‚¹
#         mature_index = None
#         for i, row in enumerate(chain_rows):
#             if pd.notna(row.get('next_bi_return')):
#                 mature_index = i
#                 break

#         if mature_index is None:
#             continue

#         mature_row = chain_rows[mature_index]
#         bsp_type = mature_row.get('bsp_type')

#         amp_field = type_to_amp_field.get(bsp_type)
#         if not amp_field:
#             print(f"[âš ] Unknown bsp_type '{bsp_type}', skipping chain {key}")
#             continue

#         mature_amp = mature_row.get(amp_field)
#         #print(mature_amp)
#         if mature_amp is None or mature_amp == 0:
#             continue
#         print(f"\n[ğŸ”] Chain {key} â€” checking next_bi_return:")
#         for i, row in enumerate(chain_rows):
#             print(f"  Index {i}, klu_idx={row['klu_idx']}, next_bi_return={row.get('next_bi_return')}")
#             current_amp = row.get(amp_field)
#             #print(current_amp)
#             if i < mature_index:
#                 if current_amp is not None:
#                     row['mature_rate'] = round(min(current_amp / mature_amp, 1), 6)
#                 else:
#                     row['mature_rate'] = None
#                 #print(row['mature_rate'])
#                 row['parent_idx'] = mature_row['klu_idx']
#                 row['is_mature'] = 0

#             elif i == mature_index:
#                 row['mature_rate'] = 10
#                 row['is_mature'] = 10
#                 row['parent_idx'] = None

#             else:
#                 row['mature_rate'] = None
#                 row['parent_idx'] = None
#                 row['is_mature'] = 0

#     print("[âœ“] Post-processed mature_rate using type-specific amplitude fields.")
#     return rows
