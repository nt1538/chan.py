{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530c410b",
   "metadata": {},
   "source": [
    "# Chan Theory Machine Learning Trading System\n",
    "## Technical Documentation\n",
    "\n",
    "**Project**: Quantitative Trading System combining Chan Theory (ç¼ è®º) with Machine Learning  \n",
    "**Author**: Ning Tang  \n",
    "**Last Updated**: November 30, 2025  \n",
    "**Version**: 1.0\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Executive Summary](#executive-summary)\n",
    "2. [System Architecture](#system-architecture)\n",
    "3. [Chan Theory Foundation](#chan-theory-foundation)\n",
    "4. [Data Processing Pipeline](#data-processing-pipeline)\n",
    "5. [Feature Engineering](#feature-engineering)\n",
    "6. [Machine Learning Model](#machine-learning-model)\n",
    "7. [Trading Strategy](#trading-strategy)\n",
    "8. [Current Implementation](#current-implementation)\n",
    "9. [Performance Metrics](#performance-metrics)\n",
    "10. [Planned Improvements](#planned-improvements)\n",
    "11. [Future Development Roadmap](#future-development-roadmap)\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This project implements a sophisticated quantitative trading system that combines **Chan Theory** (ç¼ è®º), a Chinese technical analysis methodology based on fractal geometry, with **machine learning** techniques to identify profitable trading opportunities in financial markets.\n",
    "\n",
    "### Key Objectives\n",
    "\n",
    "- **Noise Reduction**: Use Chan Theory's hierarchical five-layer filtering system to remove market noise\n",
    "- **Pattern Recognition**: Identify Buy/Sell Points (BSPoints) using normalized sliding window approaches\n",
    "- **Predictive Modeling**: Train XGBoost models to predict profitable trades based on historical pattern repetition\n",
    "- **Systematic Trading**: Execute trades systematically with proper risk management and realistic execution constraints\n",
    "\n",
    "### Primary Focus\n",
    "\n",
    "- **Market**: S&P 500 (^GSPC / SPY)\n",
    "- **Timeframe**: 5-minute K-line data\n",
    "- **Data Range**: 2000-2024 (multiple years of historical data)\n",
    "- **Dataset Size**: ~6,000 BSPoints with 60+ engineered features for a year of K-line data\n",
    "\n",
    "---\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "### High-Level Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     Data Acquisition Layer                   â”‚\n",
    "â”‚   (Yahoo Finance / CSV / Real-time Data Sources)            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â”‚\n",
    "                       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   Chan Theory Engine                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚  K-Line Processing â†’ Fractal Formation â†’ Bi Strokes  â”‚  â”‚\n",
    "â”‚  â”‚  â†’ Segment Analysis â†’ Central Zone Detection         â”‚  â”‚\n",
    "â”‚  â”‚  â†’ BSPoint Identification (Types: 1, 1p, 2, 2s, 3a, 3b)â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚              (Sliding Window: 500-3000 K-lines)             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â”‚\n",
    "                       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              Feature Engineering Layer                       â”‚\n",
    "â”‚  â€¢ Chan-specific features (divergence, Bi amplitude, etc.)  â”‚\n",
    "â”‚  â€¢ Technical indicators (MACD, RSI, KDJ, DMI, etc.)        â”‚\n",
    "â”‚  â€¢ Price action patterns                                    â”‚\n",
    "â”‚  â€¢ Multi-horizon returns (1, 5, 10, 20 periods)            â”‚\n",
    "â”‚  â€¢ Normalization & pattern-based features                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â”‚\n",
    "                       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                ML Training & Prediction                      â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚  Training: 30-day rolling window                     â”‚  â”‚\n",
    "â”‚  â”‚  Validation: Latest 1-day data for threshold tuning  â”‚  â”‚\n",
    "â”‚  â”‚  Model: XGBoost (separate for Buy/Sell)            â”‚  â”‚\n",
    "â”‚  â”‚  Target: Predict profitable BSPoints                â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â”‚\n",
    "                       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                Trading Execution Layer                       â”‚\n",
    "â”‚  â€¢ Threshold-based signal filtering                         â”‚\n",
    "â”‚  â€¢ Position sizing (100% on $10,000 initial capital)       â”‚\n",
    "â”‚  â€¢ Transaction cost simulation                              â”‚\n",
    "â”‚  â€¢ Real-time price execution validation                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Component Details\n",
    "\n",
    "#### 1. **Data Processing Components**\n",
    "\n",
    "- **SlidingWindowChan**: Core Chan analysis engine with configurable window sizes (500-3000 K-lines)\n",
    "- **NormalizedSlidingWindowChan**: Enhanced version with built-in normalization for pattern recognition\n",
    "- **CSV_API**: Custom data handling for historical datasets\n",
    "- **YahooFinanceAPI**: Real-time data integration\n",
    "\n",
    "#### 2. **Chan Theory Components**\n",
    "\n",
    "- **KLine_Unit**: Basic K-line data structure\n",
    "- **KLine_Combiner**: Merges K-lines using Chan Theory rules\n",
    "- **Bi**: Stroke identification (up/down price movements)\n",
    "- **Seg**: Segment analysis (higher-level structures)\n",
    "- **ZS**: Central zone (ä¸­æž¢) detection\n",
    "- **BSPoint**: Buy/Sell point identification and classification\n",
    "\n",
    "#### 3. **Feature Engineering Components**\n",
    "\n",
    "- **CFeatures**: Chan-specific feature extraction\n",
    "- **Technical Indicators**: MACD, RSI, KDJ, DMI, Bollinger Bands, etc.\n",
    "- **Alpha158Calculator**: Quantitative feature library\n",
    "- **Pattern Recognition**: Candlestick patterns, support/resistance, trend detection\n",
    "\n",
    "#### 4. **Machine Learning Components**\n",
    "\n",
    "- **XGBoost Models**: Separate models for buy and sell signals\n",
    "- **Threshold Optimizer**: Validation-based threshold tuning\n",
    "- **Walk-Forward Validation**: Time-based cross-validation\n",
    "- **Daily Rolling Window**: Realistic backtesting framework\n",
    "\n",
    "---\n",
    "\n",
    "## Chan Theory Foundation\n",
    "\n",
    "### What is Chan Theory (ç¼ è®º)?\n",
    "\n",
    "Chan Theory is a sophisticated technical analysis methodology developed by Chinese trader \"ç¼ ä¸­è¯´ç¦…\" (Entangled Zen). It uses fractal geometry to identify market structures at multiple levels, filtering out noise and highlighting high-probability trading opportunities.\n",
    "\n",
    "### Five-Layer Hierarchical Filtering\n",
    "\n",
    "Chan Theory processes raw price data through five hierarchical layers:\n",
    "\n",
    "1. **Layer 1: Raw K-Line Data**\n",
    "   - Input: OHLCV (Open, High, Low, Close, Volume) data\n",
    "   - Timeframe: 5-minute bars for high-frequency analysis\n",
    "\n",
    "2. **Layer 2: Fractal Formation**\n",
    "   - Merges adjacent K-lines using inclusion rules\n",
    "   - Creates clean fractal structures\n",
    "   - Removes ~30-40% of noise\n",
    "\n",
    "3. **Layer 3: Bi (ç¬”) - Strokes**\n",
    "   - Identifies directional price movements\n",
    "   - Minimum requirement: 3+ fractals in one direction\n",
    "   - **Types**: Up Bi, Down Bi\n",
    "\n",
    "4. **Layer 4: Seg (æ®µ) - Segments**\n",
    "   - Higher-level trend structures\n",
    "   - Composed of multiple Bi strokes\n",
    "   - Contains at least one Central Zone (ä¸­æž¢)\n",
    "\n",
    "5. **Layer 5: Central Zone (ZS - ä¸­æž¢)**\n",
    "   - Key equilibrium areas where price consolidates\n",
    "   - Defined by overlapping Bi strokes\n",
    "   - Critical for identifying trend reversals\n",
    "\n",
    "\n",
    "### Buy/Sell Point Classification\n",
    "\n",
    "Chan Theory identifies six main types of BSPoints:\n",
    "\n",
    "| Type | Name | Description | Signal Strength |\n",
    "|------|------|-------------|-----------------|\n",
    "| **1** | First Type | Divergence + ZS breakout | Strong |\n",
    "| **1p** | Pseudo First | Similar to Type 1 but weaker confirmation | Medium |\n",
    "| **2** | Second Type | Retracement after Type 1 | Medium-Strong |\n",
    "| **2s** | Second Sub-level | Sub-level retracement | Medium |\n",
    "| **3a** | Third Type A | Continuation pattern | Medium |\n",
    "| **3b** | Third Type B | Weakest continuation | Weak |\n",
    "\n",
    "### Key Chan Theory Concepts Used in This System\n",
    "\n",
    "1. **Divergence Rate**: Measures MACD divergence strength between peaks/troughs\n",
    "2. **Bi Amplitude**: Price movement magnitude within a Bi stroke\n",
    "3. **Bi K-line Count**: Number of K-lines in a Bi stroke\n",
    "4. **ZS Height**: Vertical distance of Central Zone\n",
    "5. **Retrace Rate**: How much price retraces into previous structure\n",
    "6. **Break Bi**: The Bi that breaks out of a Central Zone\n",
    "\n",
    "---\n",
    "\n",
    "## Data Processing Pipeline\n",
    "\n",
    "### Step 1: Data Acquisition\n",
    "\n",
    "```python\n",
    "# Example: Loading S&P 500 5-minute data\n",
    "from Common.CEnum import DATA_SRC, KL_TYPE, AUTYPE\n",
    "from ChanConfig import CChanConfig\n",
    "\n",
    "config = CChanConfig({\n",
    "    \"cal_kdj\": True,\n",
    "    \"cal_dmi\": True,\n",
    "    \"cal_rsi\": True,\n",
    "    \"bi_strict\": True,\n",
    "    \"bs_type\": '1,2,3a,1p,2s,3b',\n",
    "})\n",
    "\n",
    "chan = SlidingWindowChan(\n",
    "    code=\"^GSPC\",\n",
    "    begin_time=\"2024-01-01\",\n",
    "    end_time=\"2024-12-31\",\n",
    "    data_src=DATA_SRC.CSV,\n",
    "    lv_list=[KL_TYPE.K_5M],\n",
    "    config=config,\n",
    "    autype=AUTYPE.QFQ,\n",
    "    max_klines=500  # Sliding window size\n",
    ")\n",
    "```\n",
    "\n",
    "### Step 2: Sliding Window Processing\n",
    "\n",
    "The system uses a **sliding window approach** to process large datasets efficiently:\n",
    "\n",
    "- **Window Size**: 500-3000 K-lines (configurable)\n",
    "- **Processing**: Sequential, one window at a time\n",
    "- **BSPoint Preservation**: All identified BSPoints are stored across windows\n",
    "- **Performance**: 10-50x faster than batch processing entire dataset\n",
    "\n",
    "**Benefits**:\n",
    "- Handles multi-year datasets without memory issues\n",
    "- Realistic simulation of real-time processing\n",
    "- Captures BSPoint evolution as new data arrives\n",
    "\n",
    "### Step 3: BSPoint Detection\n",
    "\n",
    "```python\n",
    "# Process data in sliding windows\n",
    "for snapshot_idx, snapshot in enumerate(chan.step_load()):\n",
    "    # Chan analysis runs on current window\n",
    "    # BSPoints detected and stored automatically\n",
    "    pass\n",
    "\n",
    "# Retrieve all detected BSPoints\n",
    "all_bsp = chan.get_all_historical_bsp()\n",
    "print(f\"Total BSPoints detected: {len(all_bsp)}\")\n",
    "```\n",
    "\n",
    "### Step 4: Data Chronological Integrity\n",
    "\n",
    "**Critical Requirement**: Data must be processed in chronological order\n",
    "\n",
    "- Chan Theory depends on sequential analysis\n",
    "- Future data cannot influence past BSPoint detection (no look-ahead bias)\n",
    "- Timestamps must be strictly monotonically increasing\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "### Feature Categories (161 Total Features)\n",
    "\n",
    "#### 1. **Basic K-Line Features** (7 features)\n",
    "- `klu_idx`: K-line index\n",
    "- `timestamp`: Timestamp\n",
    "- `klu_open`, `klu_high`, `klu_low`, `klu_close`: OHLC prices\n",
    "- `klu_volume`: Trading volume\n",
    "\n",
    "#### 2. **BSPoint Metadata** (6 features)\n",
    "- `bsp_type`: BSPoint type (1, 1p, 2, 2s, 3a, 3b)\n",
    "- `bsp_types`: Combined types if multiple\n",
    "- `is_buy`: Buy (1) or Sell (0) signal\n",
    "- `direction`: \"up\" or \"down\"\n",
    "- `has_profit_target`: Boolean flag\n",
    "- `profit_target_pct`, `profit_target_distance`: Target metrics\n",
    "\n",
    "#### 3. **Chan Theory Features** (30+ features)\n",
    "\n",
    "**BSP Type 1 Features**:\n",
    "- `feat_divergence_rate`: MACD divergence strength\n",
    "- `feat_bsp1_bi_amp`: Bi amplitude\n",
    "- `feat_bsp1_bi_klu_cnt`: K-line count in Bi\n",
    "- `feat_bsp1_bi_amp_rate`: Normalized amplitude\n",
    "- `feat_zs_cnt`: Number of Central Zones\n",
    "\n",
    "**BSP Type 2 Features**:\n",
    "- `feat_bsp2_retrace_rate`: Retracement percentage\n",
    "- `feat_bsp2_break_bi_amp`: Breaking Bi amplitude\n",
    "- `feat_bsp2_break_bi_klu_cnt`: Breaking Bi K-line count\n",
    "- `feat_bsp2_bi_amp`, `feat_bsp2_bi_klu_cnt`: Current Bi metrics\n",
    "\n",
    "**BSP Type 2s Features** (sub-level):\n",
    "- Similar to Type 2 but with `feat_bsp2s_*` prefix\n",
    "- `feat_bsp2s_lv`: Sub-level depth\n",
    "\n",
    "**BSP Type 3 Features**:\n",
    "- `feat_bsp3_zs_height`: Central Zone height\n",
    "- `feat_bsp3_bi_amp`: Type 3 Bi amplitude\n",
    "- `feat_bsp3_bi_klu_cnt`: K-line count\n",
    "\n",
    "#### 4. **Technical Indicators** (50+ features)\n",
    "\n",
    "**MACD** (4 features):\n",
    "- `feat_macd_value`, `macd_value`: MACD histogram\n",
    "- `feat_macd_dea`, `macd_dea`: Signal line\n",
    "- `feat_macd_diff`, `macd_dif`: DIF line\n",
    "- `macd_signal`: Buy/Sell signal\n",
    "\n",
    "**RSI** (3 features):\n",
    "- `feat_rsi`, `rsi`: RSI value\n",
    "- `rsi_oversold`, `rsi_overbought`: Binary flags\n",
    "\n",
    "**KDJ** (6 features):\n",
    "- `feat_kdj_k`, `kdj_k`: K value\n",
    "- `feat_kdj_d`, `kdj_d`: D value\n",
    "- `feat_kdj_j`, `kdj_j`: J value\n",
    "- `kdj_oversold`, `kdj_overbought`: Binary flags\n",
    "\n",
    "**DMI** (4 features):\n",
    "- `dmi_plus`: +DI (positive directional indicator)\n",
    "- `dmi_minus`: -DI (negative directional indicator)\n",
    "- `dmi_adx`: ADX (trend strength)\n",
    "- `dmi_trend_up`: Trend direction flag\n",
    "\n",
    "**Moving Averages** (18 features):\n",
    "- SMA: 5, 10, 20, 50 periods\n",
    "- EMA: 12, 26, 50 periods\n",
    "- Position flags: `price_above_sma_*`, `price_above_ema_*`\n",
    "\n",
    "**Other Indicators**:\n",
    "- `atr`, `atr_ratio`: Average True Range\n",
    "- `stoch_k`, `stoch_d`: Stochastic oscillator\n",
    "- `roc_5`, `roc_10`, `roc_20`: Rate of Change\n",
    "- `williams_r`: Williams %R\n",
    "- `cci`: Commodity Channel Index\n",
    "- `mfi`: Money Flow Index\n",
    "- `tsi`: True Strength Index\n",
    "- `uo`: Ultimate Oscillator\n",
    "- `psar`: Parabolic SAR\n",
    "\n",
    "#### 5. **Candlestick Patterns** (18 features)\n",
    "- `candle_doji`, `candle_hammer`, `candle_shooting_star`\n",
    "- `candle_spinning_top`, `candle_marubozu`\n",
    "- `candle_bullish_engulfing`, `candle_bearish_engulfing`\n",
    "- `candle_morning_star`, `candle_evening_star`\n",
    "- `candle_three_white_soldiers`, `candle_three_black_crows`\n",
    "- And more...\n",
    "\n",
    "#### 6. **Price Action Features** (10 features)\n",
    "- `price_near_support`, `price_near_resistance`\n",
    "- `price_breakout_up`, `price_breakout_down`\n",
    "- `price_higher_highs`, `price_lower_lows`\n",
    "- `price_double_top`, `price_double_bottom`\n",
    "- `price_consolidation`, `price_triangle`, `price_flag`\n",
    "\n",
    "#### 7. **Volume Features** (6 features)\n",
    "- `volume_volume_spike`, `volume_volume_dry_up`\n",
    "- `volume_accumulation`, `volume_distribution`\n",
    "- `volume_climax_volume`\n",
    "- `volume_price_trend`\n",
    "\n",
    "#### 8. **Price Statistics** (7 features)\n",
    "- `price_change_pct`: Percentage change\n",
    "- `high_low_spread_pct`: High-low range\n",
    "- `upper_shadow`, `lower_shadow`: Candlestick shadows\n",
    "- `body_size`: Candlestick body\n",
    "- `is_bullish_candle`: Bullish flag\n",
    "- `feat_volume`: Volume feature\n",
    "\n",
    "#### 9. **Target Variables** (13 features)\n",
    "\n",
    "**Important Note**: **look-ahead bias** must be excluded from training, include the next_bi features and the exit_ features\n",
    "\n",
    "### Feature Normalization Strategy\n",
    "\n",
    "**Why Normalization Matters**:\n",
    "- Pattern recognition requires **relative patterns**, not absolute prices\n",
    "- Same pattern can occur at different price levels\n",
    "- Normalization makes ML model generalize better\n",
    "\n",
    "**Normalization Methods**:\n",
    "1. **Z-score Normalization**: `(X - mean) / std`\n",
    "2. **Percentage-based**: Relative to current price\n",
    "3. **Ratio-based**: Relative to historical values\n",
    "\n",
    "---\n",
    "\n",
    "## Machine Learning Model\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "**Algorithm**: XGBoost (Extreme Gradient Boosting)\n",
    "\n",
    "**Why XGBoost?**\n",
    "- Handles non-linear relationships\n",
    "- Robust to outliers and missing data\n",
    "- Fast training and prediction\n",
    "- Built-in feature importance\n",
    "- Excellent for tabular data\n",
    "\n",
    "**Model Configuration**:\n",
    "```python\n",
    "# Separate models for buy and sell signals\n",
    "buy_model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sell_model = XGBRegressor(\n",
    "    # Similar configuration\n",
    ")\n",
    "```\n",
    "\n",
    "### Training Strategy\n",
    "\n",
    "#### 1. **Rolling Window Training**\n",
    "\n",
    "```\n",
    "Training Window: 30 days (e.g., Day 1-30)\n",
    "Validation: 1 day (Day 31) - for threshold tuning\n",
    "Testing: 1 day (Day 32) - for actual trading\n",
    "\n",
    "Next iteration:\n",
    "Training: Day 2-31\n",
    "Validation: Day 32\n",
    "Testing: Day 33\n",
    "\n",
    "And so on...\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Realistic simulation of production environment\n",
    "- Model adapts to recent market conditions\n",
    "- Prevents data leakage\n",
    "- Weekly model retraining keeps model fresh\n",
    "\n",
    "#### 2. **Feature Selection**\n",
    "\n",
    "**Features to EXCLUDE** (contain future information):\n",
    "- `feat_next_bi_return` âš ï¸ **CRITICAL**: Contains look-ahead bias!\n",
    "\n",
    "**Features to INCLUDE**:\n",
    "- All Chan Theory features\n",
    "- All technical indicators\n",
    "- All price action features\n",
    "- Candlestick patterns\n",
    "- Volume features\n",
    "\n",
    "#### 3. **Target Variable**\n",
    "\n",
    "**Primary Target**: `price_change_pct` (next bspoint ahead return)\n",
    "- Balances noise reduction vs. actionable timeframe\n",
    "\n",
    "### Threshold Optimization\n",
    "\n",
    "**Purpose**: Find optimal prediction threshold to maximize trading performance\n",
    "\n",
    "**Process**:\n",
    "1. Train model on training data (30 days)\n",
    "2. Generate predictions on validation data (1 day)\n",
    "3. Test multiple threshold values (e.g., 0.0, 0.1, 0.2, ..., 2.0)\n",
    "4. For each threshold:\n",
    "   - Filter BSPoints with prediction > threshold\n",
    "   - Simulate trades on validation data\n",
    "   - Calculate metrics: Sharpe ratio, profit factor, win rate\n",
    "5. Select threshold with best Sharpe ratio\n",
    "6. Apply this threshold to test data (next day)\n",
    "\n",
    "**Current Implementation**:\n",
    "```python\n",
    "# Threshold candidates\n",
    "thresholds = np.arange(0, 2.1, 0.1)\n",
    "\n",
    "# Find best threshold\n",
    "best_threshold = optimize_threshold(\n",
    "    predictions=val_predictions,\n",
    "    actuals=val_actuals,\n",
    "    metric='sharpe_ratio'\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Trading Strategy\n",
    "\n",
    "### Signal Generation\n",
    "\n",
    "**Buy Signal**: \n",
    "- BSPoint type is a buy signal (`is_buy=1`)\n",
    "- Model prediction > threshold\n",
    "\n",
    "**Sell Signal**:\n",
    "- BSPoint type is a sell signal (`is_buy=0`)\n",
    "- Model prediction > threshold\n",
    "\n",
    "### Position Sizing\n",
    "\n",
    "**Current Strategy**: 100% of capital per trade\n",
    "- Initial capital: $10,000\n",
    "- Single position at a time\n",
    "- Full capital allocation on each signal\n",
    "\n",
    "**Risk Management Considerations** (for future implementation):\n",
    "- Stop-loss levels\n",
    "- Position sizing based on volatility\n",
    "- Maximum drawdown limits\n",
    "\n",
    "### Trade Execution Logic\n",
    "\n",
    "**Current Simulation**:\n",
    "1. Signal generated at BSPoint K-line close\n",
    "2. Trade executed at next K-line open price\n",
    "3. Exit at profit target or next opposite signal\n",
    "\n",
    "**Planned Enhancement** (see [Planned Improvements](#planned-improvements)):\n",
    "1. Account for model training time delay\n",
    "2. Validate trade price is within next period's high-low range\n",
    "3. If price not available, skip trade and wait for next signal\n",
    "\n",
    "### Transaction Costs\n",
    "\n",
    "**Current**: Not implemented âš ï¸\n",
    "\n",
    "**Planned** (see [Planned Improvements](#planned-improvements)):\n",
    "- Transaction fee: 0.1% per trade (configurable)\n",
    "- Applied to both entry and exit\n",
    "- Deducted from realized profit\n",
    "\n",
    "### Performance Calculation\n",
    "\n",
    "**Metrics Computed**:\n",
    "- **Total Return**: Cumulative profit/loss\n",
    "- **Sharpe Ratio**: Risk-adjusted return\n",
    "- **Maximum Drawdown**: Largest peak-to-trough decline\n",
    "- **Win Rate**: % of profitable trades\n",
    "- **Profit Factor**: Gross profit / Gross loss\n",
    "- **Average Trade**: Mean profit per trade\n",
    "\n",
    "---\n",
    "\n",
    "## Current Implementation\n",
    "\n",
    "### System Status\n",
    "\n",
    "**âœ… Implemented**:\n",
    "1. Chan Theory engine with sliding window processing\n",
    "2. Comprehensive feature engineering (160+ features)\n",
    "3. XGBoost model training framework\n",
    "4. Rolling window backtesting\n",
    "5. Threshold optimization on validation data\n",
    "6. Performance metrics calculation\n",
    "7. Dataset generation and storage\n",
    "\n",
    "**âš ï¸ In Progress**:\n",
    "1. Transaction fee integration\n",
    "2. Execution delay modeling\n",
    "3. Real-time data integration\n",
    "\n",
    "**ðŸ“‹ Planned**:\n",
    "1. Real-time trading system\n",
    "2. System packaging and deployment\n",
    "3. Parameter configuration UI\n",
    "4. Cloud deployment (AWS)\n",
    "\n",
    "### File Structure\n",
    "\n",
    "```\n",
    "project/\n",
    "â”œâ”€â”€ Chan.py                          # Main Chan engine\n",
    "â”œâ”€â”€ ChanConfig.py                    # Configuration management\n",
    "â”œâ”€â”€ sliding_window_chan.py           # Sliding window implementation\n",
    "â”œâ”€â”€ normalized_sliding_window_chan.py # Normalized features\n",
    "â”‚\n",
    "â”œâ”€â”€ BuySellPoint/\n",
    "â”‚   â”œâ”€â”€ BS_Point.py                  # BSPoint class\n",
    "â”‚   â”œâ”€â”€ BSPointList.py               # BSPoint management\n",
    "â”‚   â””â”€â”€ BSPointConfig.py             # BSPoint configuration\n",
    "â”‚\n",
    "â”œâ”€â”€ Bi/\n",
    "â”‚   â”œâ”€â”€ Bi.py                        # Bi stroke analysis\n",
    "â”‚   â””â”€â”€ BiConfig.py                  # Bi configuration\n",
    "â”‚\n",
    "â”œâ”€â”€ Seg/\n",
    "â”‚   â”œâ”€â”€ Seg.py                       # Segment analysis\n",
    "â”‚   â””â”€â”€ SegConfig.py                 # Segment configuration\n",
    "â”‚\n",
    "â”œâ”€â”€ ZS/\n",
    "â”‚   â”œâ”€â”€ ZS.py                        # Central Zone detection\n",
    "â”‚   â””â”€â”€ ZSConfig.py                  # ZS configuration\n",
    "â”‚\n",
    "â”œâ”€â”€ KLine/\n",
    "â”‚   â”œâ”€â”€ KLine.py                     # K-line data structure\n",
    "â”‚   â”œâ”€â”€ KLine_Unit.py                # Individual K-line\n",
    "â”‚   â”œâ”€â”€ KLine_List.py                # K-line list management\n",
    "â”‚   â””â”€â”€ KLine_Combiner.py            # K-line merging\n",
    "â”‚\n",
    "â”œâ”€â”€ Math/                            # Technical indicators\n",
    "â”‚   â”œâ”€â”€ MACD.py\n",
    "â”‚   â”œâ”€â”€ RSI.py\n",
    "â”‚   â”œâ”€â”€ KDJ.py\n",
    "â”‚   â”œâ”€â”€ DMI.py\n",
    "â”‚   â”œâ”€â”€ BOLL.py\n",
    "â”‚   â””â”€â”€ ... (other indicators)\n",
    "â”‚\n",
    "â”œâ”€â”€ DataAPI/\n",
    "â”‚   â”œâ”€â”€ csvAPI.py                    # CSV data source\n",
    "â”‚   â”œâ”€â”€ YahooFinanceAPI.py           # Yahoo Finance integration\n",
    "â”‚   â””â”€â”€ ... (other data sources)\n",
    "â”‚\n",
    "â”œâ”€â”€ Plot/\n",
    "â”‚   â”œâ”€â”€ PlotDriver.py                # Visualization\n",
    "â”‚   â””â”€â”€ PlotMeta.py                  # Plot metadata\n",
    "â”‚\n",
    "â””â”€â”€ Utils/\n",
    "    â”œâ”€â”€ Features.py                  # Feature engineering\n",
    "    â”œâ”€â”€ alpha158_calculator.py       # Quantitative features\n",
    "    â””â”€â”€ export_bs_features.py        # Feature export utilities\n",
    "\n",
    "---\n",
    "\n",
    "## Planned Improvements\n",
    "\n",
    "### 1. Transaction Fee Integration âš ï¸ **HIGH PRIORITY**\n",
    "\n",
    "**Current Issue**: Trading simulations don't account for transaction costs, leading to unrealistic performance estimates.\n",
    "\n",
    "**Implementation Plan**:\n",
    "\n",
    "```python\n",
    "# Add transaction fee parameter\n",
    "TRANSACTION_FEE_PCT = 0.1  # 0.1% per trade (configurable)\n",
    "\n",
    "# Modify trade execution\n",
    "def execute_trade(entry_price, exit_price, position_size, direction):\n",
    "    \"\"\"\n",
    "    direction: 'buy' or 'sell'\n",
    "    \"\"\"\n",
    "    # Calculate gross profit\n",
    "    if direction == 'buy':\n",
    "        gross_profit = (exit_price - entry_price) * position_size\n",
    "    else:  # short\n",
    "        gross_profit = (entry_price - exit_price) * position_size\n",
    "    \n",
    "    # Deduct transaction fees\n",
    "    entry_fee = entry_price * position_size * (TRANSACTION_FEE_PCT / 100)\n",
    "    exit_fee = exit_price * position_size * (TRANSACTION_FEE_PCT / 100)\n",
    "    total_fees = entry_fee + exit_fee\n",
    "    \n",
    "    # Net profit\n",
    "    net_profit = gross_profit - total_fees\n",
    "    \n",
    "    return net_profit, total_fees\n",
    "```\n",
    "\n",
    "**Impact on Threshold Optimization**:\n",
    "- Transaction fees will be incorporated into validation metrics\n",
    "- Optimal threshold may shift higher to account for costs\n",
    "- Expected to reduce overall profitability but improve realism\n",
    "\n",
    "### 2. Execution Delay Modeling âš ï¸ **HIGH PRIORITY**\n",
    "\n",
    "**Current Issue**: Model assumes instantaneous execution after signal generation. In reality:\n",
    "- Model training takes time (seconds to minutes)\n",
    "- Price may move during this delay\n",
    "- Desired entry price may no longer be available\n",
    "\n",
    "**Real-World Scenario**:\n",
    "```\n",
    "12:00:00 - BSPoint detected, signal generated\n",
    "12:00:05 - Model starts training (30-day dataset)\n",
    "12:00:45 - Model training complete, prediction made\n",
    "12:00:50 - Trade signal issued\n",
    "12:01:00 - Next 5-minute K-line opens, try to execute\n",
    "\n",
    "Question: Is the close price from 12:00:00 still valid?\n",
    "Answer: NO - we need to check if it's within 12:01:00-12:05:00 range\n",
    "```\n",
    "\n",
    "**Implementation Plan**:\n",
    "\n",
    "```python\n",
    "# Configuration\n",
    "MODEL_TRAINING_TIME_SECONDS = 45  # Measured empirically\n",
    "TIME_BUFFER_SECONDS = 15  # Additional buffer\n",
    "\n",
    "def simulate_realistic_execution(bsp_timestamp, bsp_close_price, next_kline):\n",
    "    \"\"\"\n",
    "    Simulate realistic trade execution with time delay.\n",
    "    \n",
    "    Args:\n",
    "        bsp_timestamp: When BSPoint was detected\n",
    "        bsp_close_price: Close price at BSPoint\n",
    "        next_kline: Next K-line data after training completes\n",
    "        \n",
    "    Returns:\n",
    "        executed: Boolean - whether trade was executed\n",
    "        execution_price: Actual execution price (if executed)\n",
    "    \"\"\"\n",
    "    # Calculate when model training would complete\n",
    "    training_complete_time = bsp_timestamp + timedelta(\n",
    "        seconds=MODEL_TRAINING_TIME_SECONDS + TIME_BUFFER_SECONDS\n",
    "    )\n",
    "    \n",
    "    # Check if desired price is within next K-line's range\n",
    "    if next_kline['timestamp'] >= training_complete_time:\n",
    "        # Check if BSP close price is achievable\n",
    "        if (next_kline['low'] <= bsp_close_price <= next_kline['high']):\n",
    "            # Trade can be executed at desired price\n",
    "            return True, bsp_close_price\n",
    "        else:\n",
    "            # Price moved too far, trade skipped\n",
    "            print(f\"Trade skipped - price {bsp_close_price} not in range \"\n",
    "                  f\"[{next_kline['low']}, {next_kline['high']}]\")\n",
    "            return False, None\n",
    "    else:\n",
    "        # Training not complete yet, check subsequent K-line\n",
    "        # (Implementation continues...)\n",
    "        pass\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "# Integration into backtesting\n",
    "for idx, bsp in enumerate(bsp_list):\n",
    "    # Generate prediction (includes training time)\n",
    "    prediction = model.predict(bsp_features)\n",
    "    \n",
    "    if prediction > threshold:\n",
    "        # Try to execute trade\n",
    "        executed, exec_price = simulate_realistic_execution(\n",
    "            bsp['timestamp'], \n",
    "            bsp['klu_close'],\n",
    "            next_kline_data[idx+1]\n",
    "        )\n",
    "        \n",
    "        if executed:\n",
    "            # Record trade\n",
    "            trades.append({\n",
    "                'entry_time': next_kline_data[idx+1]['timestamp'],\n",
    "                'entry_price': exec_price,\n",
    "                # ...\n",
    "            })\n",
    "        else:\n",
    "            # Skip this signal, wait for next\n",
    "            skipped_signals += 1\n",
    "```\n",
    "\n",
    "**Expected Impact**:\n",
    "- Reduce number of executed trades (some signals will be skipped)\n",
    "- More realistic slippage modeling\n",
    "- Better alignment with production performance\n",
    "\n",
    "**Measurement Plan**:\n",
    "1. Time the Chan system processing for different window sizes\n",
    "2. Time the XGBoost training for 30-day datasets\n",
    "3. Add configurable parameters for both\n",
    "4. Report execution rate (% of signals actually executed)\n",
    "\n",
    "### 3. Real-Time Data Integration ðŸ”„ **MEDIUM PRIORITY**\n",
    "\n",
    "**Objective**: Move from historical backtesting to real-time trading capability\n",
    "\n",
    "**Requirements**:\n",
    "- Only need 30 days of historical data for model training\n",
    "- Use yfinance API for real-time data\n",
    "- Update data incrementally (new 5-minute bars)\n",
    "\n",
    "**Challenges**:\n",
    "1. **Market Hours**: Handle market open/close times\n",
    "2. **Data Quality**: Validate yfinance data completeness\n",
    "3. **Error Handling**: Reconnection logic for API failures\n",
    "4. **State Persistence**: Save Chan engine state between restarts\n",
    "\n",
    "**Testing Strategy**:\n",
    "1. Paper trading: Generate signals without real money\n",
    "2. Compare with historical backtest results\n",
    "3. Monitor execution rates and slippage\n",
    "4. Gradual rollout with small capital\n",
    "\n",
    "---\n",
    "\n",
    "## Future Development Roadmap\n",
    "\n",
    "### Phase 1: System Refinement \n",
    "\n",
    "**Week 1-2: Transaction Fees & Execution Delay**\n",
    "- [ ] Implement transaction fee parameter (0.1% default)\n",
    "- [ ] Measure Chan system + XGBoost training time\n",
    "- [ ] Implement realistic execution delay simulation\n",
    "- [ ] Validate price availability in next period's range\n",
    "- [ ] Re-run backtests with new constraints\n",
    "- [ ] Document performance impact\n",
    "\n",
    "**Week 3-4: Real-Time Integration**\n",
    "- [ ] Build yfinance data integration\n",
    "- [ ] Implement incremental data loading\n",
    "- [ ] Create real-time BSPoint detection\n",
    "- [ ] Add state persistence (save/load Chan engine)\n",
    "- [ ] Develop paper trading mode\n",
    "- [ ] Test with live market data (no real trades)\n",
    "\n",
    "### Phase 2: System Packaging \n",
    "\n",
    "**Objectives**:\n",
    "- Modularize codebase for production deployment\n",
    "- Create configuration management system\n",
    "- Build parameter optimization framework\n",
    "- Develop basic monitoring UI\n",
    "\n",
    "**Key Deliverables**:\n",
    "\n",
    "#### 2.1 Configuration System\n",
    "\n",
    "```python\n",
    "# config/trading_config.yaml\n",
    "system:\n",
    "  name: \"Chan ML Trading System\"\n",
    "  version: \"1.0.0\"\n",
    "\n",
    "data:\n",
    "  source: \"yfinance\"  # or \"csv\", \"alphavantage\"\n",
    "  symbol: \"SPY\"\n",
    "  timeframe: \"5m\"\n",
    "  lookback_days: 30\n",
    "\n",
    "chan_parameters:\n",
    "  max_klines: 500\n",
    "  bi_strict: true\n",
    "  bs_types: \"1,2,3a,1p,2s,3b\"\n",
    "  cal_kdj: true\n",
    "  cal_dmi: true\n",
    "  cal_rsi: true\n",
    "\n",
    "ml_parameters:\n",
    "  model_type: \"xgboost\"\n",
    "  n_estimators: 100\n",
    "  max_depth: 6\n",
    "  learning_rate: 0.1\n",
    "  target_variable: \"return_5\"\n",
    "  retrain_frequency: \"weekly\"\n",
    "\n",
    "trading_parameters:\n",
    "  initial_capital: 10000\n",
    "  position_size: 1.0  # 100% of capital\n",
    "  transaction_fee_pct: 0.1\n",
    "  model_training_time_sec: 45\n",
    "  execution_buffer_sec: 15\n",
    "\n",
    "risk_management:\n",
    "  max_drawdown_pct: 15\n",
    "  stop_loss_pct: 2.0  # per trade\n",
    "  max_daily_trades: 10\n",
    "\n",
    "thresholds:\n",
    "  optimization_metric: \"sharpe_ratio\"\n",
    "  search_range: [0.0, 2.0]\n",
    "  search_step: 0.1\n",
    "```\n",
    "\n",
    "#### 2.2 Modular Architecture\n",
    "\n",
    "```python\n",
    "# src/\n",
    "â”œâ”€â”€ core/\n",
    "â”‚   â”œâ”€â”€ chan_engine.py          # Chan Theory engine\n",
    "â”‚   â”œâ”€â”€ feature_engineer.py     # Feature extraction\n",
    "â”‚   â””â”€â”€ ml_model.py             # Model training/prediction\n",
    "â”‚\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ data_loader.py          # Abstract data interface\n",
    "â”‚   â”œâ”€â”€ yfinance_loader.py      # YFinance implementation\n",
    "â”‚   â”œâ”€â”€ csv_loader.py           # CSV implementation\n",
    "â”‚   â””â”€â”€ cache_manager.py        # Data caching\n",
    "â”‚\n",
    "â”œâ”€â”€ trading/\n",
    "â”‚   â”œâ”€â”€ signal_generator.py     # Signal generation\n",
    "â”‚   â”œâ”€â”€ execution_engine.py     # Trade execution\n",
    "â”‚   â”œâ”€â”€ position_manager.py     # Position tracking\n",
    "â”‚   â””â”€â”€ risk_manager.py         # Risk controls\n",
    "â”‚\n",
    "â”œâ”€â”€ backtest/\n",
    "â”‚   â”œâ”€â”€ backtest_engine.py      # Historical simulation\n",
    "â”‚   â”œâ”€â”€ performance_metrics.py  # Metrics calculation\n",
    "â”‚   â””â”€â”€ report_generator.py     # Result reporting\n",
    "â”‚\n",
    "â”œâ”€â”€ config/\n",
    "â”‚   â”œâ”€â”€ config_loader.py        # Configuration management\n",
    "â”‚   â””â”€â”€ parameter_validator.py  # Input validation\n",
    "â”‚\n",
    "â””â”€â”€ utils/\n",
    "    â”œâ”€â”€ logger.py               # Logging\n",
    "    â”œâ”€â”€ monitoring.py           # System monitoring\n",
    "    â””â”€â”€ alerting.py             # Email/SMS alerts\n",
    "```\n",
    "\n",
    "#### 2.3 Command-Line Interface\n",
    "\n",
    "```bash\n",
    "# Train model on historical data\n",
    "python main.py train --config config/trading_config.yaml --output models/\n",
    "\n",
    "# Run backtest\n",
    "python main.py backtest --config config/trading_config.yaml --start 2024-01-01 --end 2024-12-31\n",
    "\n",
    "# Optimize parameters\n",
    "python main.py optimize --config config/trading_config.yaml --metric sharpe_ratio\n",
    "\n",
    "# Run paper trading\n",
    "python main.py paper-trade --config config/trading_config.yaml\n",
    "\n",
    "# Deploy live trading\n",
    "python main.py live-trade --config config/trading_config.yaml --mode cautious\n",
    "```\n",
    "\n",
    "### Phase 3: User Interface (Weeks 9-12)\n",
    "\n",
    "**Objectives**:\n",
    "- Build web-based dashboard for monitoring\n",
    "- Create parameter tuning interface\n",
    "- Provide visualization tools\n",
    "\n",
    "**Technology Stack**:\n",
    "- **Backend**: FastAPI (Python)\n",
    "- **Frontend**: React.js or Streamlit\n",
    "- **Database**: PostgreSQL (trade history)\n",
    "- **Caching**: Redis (real-time data)\n",
    "\n",
    "\n",
    "\n",
    "#### 3.2 Parameter Configuration Interface\n",
    "\n",
    "**Web Form for Adjusting Parameters**:\n",
    "- Chan System: K-line window size, BSPoint types\n",
    "- ML Model: XGBoost hyperparameters, target variable\n",
    "- Trading: Position size, fees, stop-loss\n",
    "- Risk: Max drawdown, daily trade limits\n",
    "\n",
    "**Real-time Validation**:\n",
    "- Check parameter validity before saving\n",
    "- Show estimated impact on performance\n",
    "- Warn about risky configurations\n",
    "\n",
    "#### 3.3 Visualization Tools\n",
    "\n",
    "**Charts**:\n",
    "1. **Equity Curve**: Portfolio value over time\n",
    "2. **Drawdown Chart**: Underwater plot\n",
    "3. **BSPoint Detection**: K-line chart with detected BSPoints\n",
    "4. **Feature Importance**: Bar chart of top features\n",
    "5. **Trade Distribution**: Win/loss histogram\n",
    "6. **Signal Frequency**: Signals per day over time\n",
    "\n",
    "**Interactive Tools**:\n",
    "- Backtest parameter sweep visualization\n",
    "- Correlation matrix of features\n",
    "- BSPoint pattern explorer\n",
    "\n",
    "### Phase 4: Cloud Deployment (Weeks 13-16)\n",
    "\n",
    "**Objectives**:\n",
    "- Deploy system to AWS cloud\n",
    "- Set up monitoring and alerting\n",
    "- Implement CI/CD pipeline\n",
    "- Configure auto-scaling\n",
    "\n",
    "**Architecture**:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        AWS Cloud                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "â”‚  â”‚  EC2 Instance  â”‚â”€â”€â”€â”€â–¶â”‚  RDS Database  â”‚                 â”‚\n",
    "â”‚  â”‚  (Trading App) â”‚     â”‚  (PostgreSQL)  â”‚                 â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "â”‚           â”‚                                                  â”‚\n",
    "â”‚           â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\n",
    "â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ ElastiCache    â”‚                 â”‚\n",
    "â”‚                         â”‚ (Redis)        â”‚                 â”‚\n",
    "â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "â”‚  â”‚  S3 Storage    â”‚     â”‚  CloudWatch    â”‚                 â”‚\n",
    "â”‚  â”‚  (Models/Logs) â”‚     â”‚  (Monitoring)  â”‚                 â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "â”‚  â”‚  Lambda        â”‚     â”‚  SNS/SES       â”‚                 â”‚\n",
    "â”‚  â”‚  (Scheduled)   â”‚     â”‚  (Alerts)      â”‚                 â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "â”‚                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Components**:\n",
    "\n",
    "1. **EC2 Instance (t3.medium or larger)**\n",
    "   - Runs main trading application\n",
    "   - Handles Chan analysis + ML predictions\n",
    "   - Auto-scaling group for redundancy\n",
    "\n",
    "2. **RDS PostgreSQL**\n",
    "   - Stores trade history\n",
    "   - Configuration parameters\n",
    "   - Model performance metrics\n",
    "\n",
    "3. **ElastiCache Redis**\n",
    "   - Caches recent K-line data\n",
    "   - Stores real-time BSPoint detections\n",
    "   - Session management\n",
    "\n",
    "4. **S3 Storage**\n",
    "   - Model checkpoints\n",
    "   - Historical data archives\n",
    "   - Backtest results\n",
    "   - Application logs\n",
    "\n",
    "5. **CloudWatch**\n",
    "   - System metrics (CPU, memory, network)\n",
    "   - Application metrics (signals, trades, P&L)\n",
    "   - Custom dashboards\n",
    "   - Automated alarms\n",
    "\n",
    "6. **Lambda Functions**\n",
    "   - Scheduled model retraining\n",
    "   - Daily performance reports\n",
    "   - Data backup jobs\n",
    "   - Health checks\n",
    "\n",
    "7. **SNS/SES**\n",
    "   - Email alerts for signals\n",
    "   - SMS for critical issues\n",
    "   - Performance reports\n",
    "\n",
    "**CI/CD Pipeline**:\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/deploy.yml\n",
    "name: Deploy Trading System\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v2\n",
    "      - name: Run tests\n",
    "        run: |\n",
    "          pip install -r requirements.txt\n",
    "          pytest tests/\n",
    "  \n",
    "  deploy:\n",
    "    needs: test\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - name: Deploy to EC2\n",
    "        run: |\n",
    "          # SSH to EC2 and pull latest code\n",
    "          # Restart services\n",
    "          # Run health checks\n",
    "```\n",
    "\n",
    "**Monitoring & Alerts**:\n",
    "\n",
    "```python\n",
    "# Define alert rules\n",
    "alerts = {\n",
    "    'drawdown_exceeded': {\n",
    "        'condition': 'current_drawdown > max_drawdown_pct',\n",
    "        'action': 'stop_trading_and_notify',\n",
    "        'channels': ['email', 'sms']\n",
    "    },\n",
    "    'model_performance_degraded': {\n",
    "        'condition': 'win_rate_7d < 0.45',\n",
    "        'action': 'retrain_model_and_notify',\n",
    "        'channels': ['email']\n",
    "    },\n",
    "    'data_feed_disconnected': {\n",
    "        'condition': 'last_update_age > 10_minutes',\n",
    "        'action': 'reconnect_and_notify',\n",
    "        'channels': ['email', 'sms']\n",
    "    },\n",
    "    'execution_rate_low': {\n",
    "        'condition': 'execution_rate_today < 0.5',\n",
    "        'action': 'investigate_and_notify',\n",
    "        'channels': ['email']\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Phase 5: Advanced Features (Weeks 17+)\n",
    "\n",
    "**Research & Development**:\n",
    "\n",
    "1. **Multi-Timeframe Analysis**\n",
    "   - Combine signals from 1min, 5min, 15min, 1hour\n",
    "   - Weight predictions by timeframe alignment\n",
    "   - Expected improvement: 15-20% in Sharpe ratio\n",
    "\n",
    "2. **Ensemble Models**\n",
    "   - XGBoost + LightGBM + CatBoost\n",
    "   - Voting or stacking ensemble\n",
    "   - Reduce overfitting, improve robustness\n",
    "\n",
    "3. **Alternative Targets**\n",
    "   - Predict optimal holding period (not just return)\n",
    "   - Multi-class classification (strong buy / buy / hold / sell / strong sell)\n",
    "   - Risk-adjusted return prediction\n",
    "\n",
    "4. **Adaptive Thresholding**\n",
    "   - Dynamic threshold based on market volatility\n",
    "   - Tighter threshold in low-volatility, looser in high-volatility\n",
    "   - Reduce whipsaws during choppy markets\n",
    "\n",
    "5. **Market Regime Detection**\n",
    "   - Classify market as trending / ranging / volatile\n",
    "   - Different models for different regimes\n",
    "   - Skip trading in unfavorable regimes\n",
    "\n",
    "6. **Portfolio Diversification**\n",
    "   - Trade multiple instruments (SPY, QQQ, IWM, etc.)\n",
    "   - Correlation-based position sizing\n",
    "   - Reduce portfolio volatility\n",
    "\n",
    "7. **Reinforcement Learning**\n",
    "   - RL agent learns optimal execution timing\n",
    "   - Dynamic stop-loss and profit-taking\n",
    "   - Expected to handle complex market dynamics\n",
    "\n",
    "**Current State**: The system successfully processes historical data, generates high-quality BSPoint signals, trains predictive models, and simulates trades with realistic constraints.\n",
    "\n",
    "**Next Steps**: \n",
    "1. Implement transaction fees and execution delay modeling\n",
    "2. Integrate real-time data for paper trading\n",
    "3. Package system for production deployment\n",
    "4. Deploy to cloud infrastructure\n",
    "\n",
    "**Long-term Vision**: Create a fully-automated, cloud-based trading system that adapts to market conditions, manages risk intelligently, and generates consistent returns.\n",
    "\n",
    "---\n",
    "\n",
    "**Document Version**: 1.0  \n",
    "**Date**: November 30, 2025  \n",
    "**Author**: Ning Tang  \n",
    "\n",
    "---\n",
    "\n",
    "*This documentation is a living document and will be updated as the project evolves.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Your Chan imports\n",
    "from chan_streamer import ChanStreamer\n",
    "from ChanConfig import CChanConfig\n",
    "from Common.CEnum import KL_TYPE, DATA_SRC, AUTYPE\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Helper: Profit targets using BEST within 24h (from your script)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_profit_targets_best_within_24h(\n",
    "    bs_points_with_features: List[Dict],\n",
    "    time_window_bars: int = 288\n",
    ") -> Dict[int, Dict]:\n",
    "    \"\"\"\n",
    "    Calculate profit targets using the BEST reverse signal within a time window.\n",
    "    For BUY signals: max SELL price within window.\n",
    "    For SELL signals: min BUY price within window.\n",
    "    \"\"\"\n",
    "    print(f\"[ðŸŽ¯] STEP 2: Calculating profit targets using BEST within {time_window_bars} bars (~24h)...\")\n",
    "\n",
    "    # Sort by klu_idx\n",
    "    bs_points_with_features.sort(key=lambda x: x['klu_idx'])\n",
    "    profit_targets = {}\n",
    "\n",
    "    for i, data in enumerate(bs_points_with_features):\n",
    "        current_direction = data['is_buy']  # 1 = buy, 0 = sell\n",
    "        entry_price = data['klu_close']\n",
    "        entry_idx = data['klu_idx']\n",
    "\n",
    "        # Initialize\n",
    "        profit_targets[entry_idx] = {\n",
    "            'profit_target_pct': None,\n",
    "            'profit_target_distance': None,\n",
    "            'has_profit_target': 0,\n",
    "            'exit_type': None,\n",
    "            'exit_klu_idx': None,\n",
    "            'exit_price': None,\n",
    "        }\n",
    "\n",
    "        window_end_idx = entry_idx + time_window_bars\n",
    "        candidates_in_window = []\n",
    "        fallback_next_reverse = None\n",
    "\n",
    "        for j in range(i + 1, len(bs_points_with_features)):\n",
    "            future_data = bs_points_with_features[j]\n",
    "            future_idx = future_data['klu_idx']\n",
    "\n",
    "            # Opposite direction\n",
    "            if future_data['is_buy'] != current_direction:\n",
    "                if fallback_next_reverse is None:\n",
    "                    fallback_next_reverse = future_data\n",
    "                if future_idx <= window_end_idx:\n",
    "                    candidates_in_window.append(future_data)\n",
    "\n",
    "        best_exit = None\n",
    "        if candidates_in_window:\n",
    "            if current_direction:  # buy\n",
    "                best_exit = max(candidates_in_window, key=lambda x: x['klu_close'])\n",
    "                exit_type = 'best_24h'\n",
    "            else:  # sell\n",
    "                best_exit = min(candidates_in_window, key=lambda x: x['klu_close'])\n",
    "                exit_type = 'best_24h'\n",
    "        elif fallback_next_reverse:\n",
    "            best_exit = fallback_next_reverse\n",
    "            exit_type = 'fallback_next'\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        exit_price = best_exit['klu_close']\n",
    "        if current_direction:  # BUY -> SELL\n",
    "            profit_pct = (exit_price - entry_price) / entry_price * 100\n",
    "        else:  # SELL -> BUY\n",
    "            profit_pct = (entry_price - exit_price) / entry_price * 100\n",
    "\n",
    "        profit_targets[entry_idx] = {\n",
    "            'profit_target_pct': profit_pct,\n",
    "            'profit_target_distance': best_exit['klu_idx'] - entry_idx,\n",
    "            'has_profit_target': 1,\n",
    "            'exit_type': exit_type,\n",
    "            'exit_klu_idx': best_exit['klu_idx'],\n",
    "            'exit_price': exit_price,\n",
    "        }\n",
    "\n",
    "    valid_targets = [v for v in profit_targets.values() if v['has_profit_target'] == 1]\n",
    "    if valid_targets:\n",
    "        profits = [v['profit_target_pct'] for v in valid_targets]\n",
    "        distances = [v['profit_target_distance'] for v in valid_targets]\n",
    "        exit_types = [v['exit_type'] for v in valid_targets]\n",
    "\n",
    "        best_24h_count = sum(1 for et in exit_types if et == 'best_24h')\n",
    "        fallback_count = sum(1 for et in exit_types if et == 'fallback_next')\n",
    "\n",
    "        print(f\"[ðŸ“Š] Profit Target Summary (BEST within 24h):\")\n",
    "        print(f\"  Total BS points: {len(bs_points_with_features)}\")\n",
    "        print(f\"  Points with targets: {len(valid_targets)} ({len(valid_targets)/len(bs_points_with_features)*100:.1f}%)\")\n",
    "        print(f\"  Exit types:\")\n",
    "        print(f\"    - Best within 24h: {best_24h_count} ({best_24h_count/len(valid_targets)*100:.1f}%)\")\n",
    "        print(f\"    - Fallback (next reverse): {fallback_count} ({fallback_count/len(valid_targets)*100:.1f}%)\")\n",
    "        print(f\"  Average profit: {np.mean(profits):.2f}%\")\n",
    "        print(f\"  Median profit: {np.median(profits):.2f}%\")\n",
    "        print(f\"  Best profit: {max(profits):.2f}%\")\n",
    "        print(f\"  Worst result: {min(profits):.2f}%\")\n",
    "        print(f\"  Average distance: {np.mean(distances):.1f} bars\")\n",
    "        print(f\"  Profitable trades: {sum(1 for p in profits if p > 0)}/{len(profits)} ({sum(1 for p in profits if p > 0)/len(profits)*100:.1f}%)\")\n",
    "\n",
    "    return profit_targets\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Prepare ML dataset (same style as your previous script)\n",
    "# ============================================================\n",
    "\n",
    "def prepare_ml_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    print(\"[ðŸ”§] Preparing final ML dataset...\")\n",
    "\n",
    "    categorical_cols = ['direction', 'timestamp']\n",
    "    binary_cols = [col for col in df.columns\n",
    "                   if col.endswith(('_signal', '_oversold', '_overbought', '_positive', '_up', '_trend_up'))]\n",
    "    binary_cols.extend(['is_buy', 'is_bullish_candle', 'has_profit_target'])\n",
    "\n",
    "    numeric_cols = [col for col in df.select_dtypes(include=[np.number]).columns\n",
    "                    if col not in categorical_cols and col not in binary_cols]\n",
    "\n",
    "    if numeric_cols:\n",
    "        num_imputer = SimpleImputer(strategy='mean')\n",
    "        df[numeric_cols] = num_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "    if binary_cols:\n",
    "        existing_binary_cols = [col for col in binary_cols if col in df.columns]\n",
    "        if existing_binary_cols:\n",
    "            bin_imputer = SimpleImputer(strategy='most_frequent')\n",
    "            df[existing_binary_cols] = bin_imputer.fit_transform(df[existing_binary_cols])\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('unknown')\n",
    "\n",
    "    if 'direction' in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df['direction_encoded'] = le.fit_transform(df['direction'].astype(str))\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    num_cols_final = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols_final] = df[num_cols_final].fillna(0)\n",
    "\n",
    "    print(f\"[âœ…] Dataset prepared with {len(df)} samples and {len(df.columns)} features\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Feature column selection (similar logic to your backtest)\n",
    "# ============================================================\n",
    "\n",
    "def get_feature_columns(df: pd.DataFrame, target_col: str = \"profit_target_pct\") -> List[str]:\n",
    "    exclude_patterns = [\n",
    "        'timestamp', 'bsp_type', 'direction',\n",
    "        'snapshot_', 'exit_', 'klu_idx',\n",
    "        'date'\n",
    "    ]\n",
    "\n",
    "    extra_exclude = [\n",
    "        target_col,\n",
    "        'profit_target_pct',\n",
    "        'profit_target_distance',\n",
    "        'has_profit_target'\n",
    "    ]\n",
    "\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        if col in extra_exclude:\n",
    "            continue\n",
    "        if any(pat in col for pat in exclude_patterns):\n",
    "            continue\n",
    "        cols.append(col)\n",
    "\n",
    "    # If both raw and encoded exist, drop the raw\n",
    "    if 'direction' in cols and 'direction_encoded' in cols:\n",
    "        cols.remove('direction')\n",
    "\n",
    "    return sorted(cols)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. XGBoost helpers: metrics & threshold optimization\n",
    "# ============================================================\n",
    "\n",
    "def calc_reg_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred) if len(np.unique(y_true)) > 1 else 0\n",
    "    acc = np.mean((y_true > 0) == (y_pred > 0)) * 100\n",
    "    return dict(MSE=mse, RMSE=rmse, MAE=mae, R2=r2, Accuracy=acc)\n",
    "\n",
    "\n",
    "def optimize_thresholds_with_fee(signals_df: pd.DataFrame,\n",
    "                                 transaction_fee_pct: float) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Grid search for thresholds on a *threshold day*, considering transaction fee.\n",
    "    Fee is approximated as 2 * transaction_fee_pct per round-trip in % terms.\n",
    "    \"\"\"\n",
    "    if len(signals_df) == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    thresholds = np.linspace(-0.5, 3.0, 29)  # -0.5% to 3.0%\n",
    "\n",
    "    best_score = -1e9\n",
    "    best_bt = 0.0\n",
    "    best_st = 0.0\n",
    "    roundtrip_fee_pct = 2 * transaction_fee_pct * 100.0\n",
    "\n",
    "    buy_df = signals_df[signals_df['direction'] == 'buy']\n",
    "    sell_df = signals_df[signals_df['direction'] == 'sell']\n",
    "\n",
    "    for bt in thresholds:\n",
    "        for st in thresholds:\n",
    "            val_b = buy_df[buy_df['predicted_profit_pct'] >= bt]\n",
    "            val_s = sell_df[sell_df['predicted_profit_pct'] >= st]\n",
    "\n",
    "            if len(val_b) == 0 and len(val_s) == 0:\n",
    "                continue\n",
    "\n",
    "            # Approximate realized profit = label - round-trip fee\n",
    "            b_ret = (val_b['profit_target_pct'] - roundtrip_fee_pct).mean() if len(val_b) > 0 else 0.0\n",
    "            s_ret = (val_s['profit_target_pct'] - roundtrip_fee_pct).mean() if len(val_s) > 0 else 0.0\n",
    "\n",
    "            n_b, n_s = len(val_b), len(val_s)\n",
    "            tot = n_b + n_s\n",
    "            combined = (n_b * b_ret + n_s * s_ret) / tot if tot > 0 else 0.0\n",
    "\n",
    "            if combined > best_score:\n",
    "                best_score = combined\n",
    "                best_bt = bt\n",
    "                best_st = st\n",
    "\n",
    "    return best_bt, best_st\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Backtest single day using BSP signals + transaction fee\n",
    "# ============================================================\n",
    "\n",
    "def backtest_one_day_signals(signals_df: pd.DataFrame,\n",
    "                             buy_threshold: float,\n",
    "                             sell_threshold: float,\n",
    "                             initial_capital: float,\n",
    "                             position_size: float,\n",
    "                             transaction_fee_pct: float,\n",
    "                             verbose: bool = False) -> Tuple[Dict, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Simple long-only / flat strategy with prints:\n",
    "    - When BUY is executed, print entry time & close price.\n",
    "    - When SELL is executed, print exit time, close price, and return vs previous buy.\n",
    "    \"\"\"\n",
    "    if len(signals_df) == 0:\n",
    "        return {\n",
    "            'final_value': initial_capital,\n",
    "            'return_pct': 0.0,\n",
    "            'trades': 0,\n",
    "            'win_rate': 0.0,\n",
    "            'signals': 0,\n",
    "            'buy_signals': 0,\n",
    "            'sell_signals': 0,\n",
    "        }, []\n",
    "\n",
    "    df = signals_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    cash = initial_capital\n",
    "    shares = 0.0\n",
    "    entry_price = None\n",
    "    entry_time = None\n",
    "    trades: List[Dict] = []\n",
    "\n",
    "    # per-side fee (e.g. 0.001 = 0.1%)\n",
    "    per_side_fee = transaction_fee_pct\n",
    "\n",
    "    def open_position(price, time_):\n",
    "        nonlocal cash, shares, entry_price, entry_time\n",
    "        trade_cap = cash * position_size\n",
    "        if trade_cap <= 0:\n",
    "            return False\n",
    "\n",
    "        # pay entry fee on the capital put to work\n",
    "        effective_capital = trade_cap * (1 - per_side_fee)\n",
    "        shares = effective_capital / price\n",
    "        cash -= trade_cap  # reserve that amount\n",
    "        entry_price = price\n",
    "        entry_time = time_\n",
    "\n",
    "        trades.append({\n",
    "            'entry_time': time_,\n",
    "            'entry_price': price,\n",
    "            'direction': 'buy'\n",
    "        })\n",
    "\n",
    "        # ðŸ”” print BUY alert\n",
    "        print(f\"[TRADE] BUY confirmed at {time_} | close price = {price:.4f}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def close_position(price, time_):\n",
    "        nonlocal cash, shares, entry_price, entry_time\n",
    "        if shares <= 0:\n",
    "            return\n",
    "\n",
    "        # gross exit\n",
    "        gross_exit = shares * price\n",
    "        # pay exit fee on exit value\n",
    "        net_exit = gross_exit * (1 - per_side_fee)\n",
    "\n",
    "        # approximate capital at entry (before entry fee)\n",
    "        trade_cap = shares * entry_price if entry_price is not None else 0.0\n",
    "        pnl = net_exit - trade_cap\n",
    "        ret_pct = (pnl / trade_cap * 100) if trade_cap > 0 else 0.0\n",
    "\n",
    "        cash += net_exit\n",
    "\n",
    "        if trades:\n",
    "            trades[-1].update({\n",
    "                'exit_time': time_,\n",
    "                'exit_price': price,\n",
    "                'pnl': pnl,\n",
    "                'return_pct': ret_pct\n",
    "            })\n",
    "\n",
    "        # ðŸ”” print SELL alert with return\n",
    "        print(\n",
    "            f\"[TRADE] SELL confirmed at {time_} | close price = {price:.4f} | \"\n",
    "            f\"trade return = {ret_pct:.2f}%\"\n",
    "        )\n",
    "\n",
    "        shares = 0.0\n",
    "        entry_price = None\n",
    "        entry_time = None\n",
    "\n",
    "    # main loop over signals\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row['timestamp']\n",
    "        price = row['klu_close']\n",
    "        pred = row['predicted_profit_pct']\n",
    "        direction = row['direction']\n",
    "\n",
    "        if direction == 'buy':\n",
    "            if shares == 0 and pred >= buy_threshold:\n",
    "                open_position(price, ts)\n",
    "\n",
    "        elif direction == 'sell':\n",
    "            if shares > 0 and pred >= sell_threshold:\n",
    "                close_position(price, ts)\n",
    "\n",
    "    # force close at day end if still open\n",
    "    if shares > 0:\n",
    "        last_row = df.iloc[-1]\n",
    "        close_position(last_row['klu_close'], last_row['timestamp'])\n",
    "\n",
    "    final_value = cash\n",
    "    ret_pct = (final_value / initial_capital - 1) * 100 if initial_capital > 0 else 0.0\n",
    "    completed = [t for t in trades if 'exit_price' in t]\n",
    "    win_trades = [t for t in completed if t.get('return_pct', 0) > 0]\n",
    "    win_rate = (len(win_trades) / len(completed) * 100) if completed else 0.0\n",
    "\n",
    "    buy_signals = (df['direction'] == 'buy').sum()\n",
    "    sell_signals = (df['direction'] == 'sell').sum()\n",
    "\n",
    "    result = {\n",
    "        'final_value': final_value,\n",
    "        'return_pct': ret_pct,\n",
    "        'trades': len(completed),\n",
    "        'win_rate': win_rate,\n",
    "        'signals': len(df),\n",
    "        'buy_signals': buy_signals,\n",
    "        'sell_signals': sell_signals,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"    Day summary: trades={len(completed)}, \"\n",
    "            f\"win_rate={win_rate:.1f}%, day_return={ret_pct:.2f}%\"\n",
    "        )\n",
    "\n",
    "    return result, completed\n",
    "\n",
    "# ============================================================\n",
    "# 6. Buy & Hold benchmark from raw SPY CSV\n",
    "# ============================================================\n",
    "\n",
    "def calc_buy_hold_daily(csv_path: str,\n",
    "                        start_time: str,\n",
    "                        end_time: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assumes CSV has a datetime column (named 'timestamp' or first col) and 'close' or 'Close'.\n",
    "    Computes daily close and cumulative return series.\n",
    "    \"\"\"\n",
    "    raw = pd.read_csv(csv_path)\n",
    "    # Try to infer datetime column\n",
    "    if 'timestamp' in raw.columns:\n",
    "        raw['timestamp'] = pd.to_datetime(raw['timestamp'])\n",
    "    else:\n",
    "        raw.iloc[:, 0] = pd.to_datetime(raw.iloc[:, 0])\n",
    "        raw.rename(columns={raw.columns[0]: 'timestamp'}, inplace=True)\n",
    "\n",
    "    # Try to infer close column\n",
    "    close_col = 'close'\n",
    "    for c in ['close', 'Close', 'adj_close', 'Adj Close']:\n",
    "        if c in raw.columns:\n",
    "            close_col = c\n",
    "            break\n",
    "\n",
    "    mask = (raw['timestamp'] >= pd.to_datetime(start_time)) & (raw['timestamp'] <= pd.to_datetime(end_time))\n",
    "    raw = raw[mask].copy()\n",
    "    raw['date'] = raw['timestamp'].dt.date\n",
    "\n",
    "    daily = raw.groupby('date')[close_col].agg(['first', 'last'])\n",
    "    daily.rename(columns={'first': 'open', 'last': 'close'}, inplace=True)\n",
    "    daily['return_pct'] = (daily['close'] / daily['open'] - 1) * 100\n",
    "\n",
    "    # Cumulative from first date\n",
    "    first_price = daily['open'].iloc[0]\n",
    "    daily['cum_return_pct'] = (daily['close'] / first_price - 1) * 100\n",
    "\n",
    "    return daily.reset_index().rename(columns={'date': 'date'})\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. Generate BSP dataset from SlidingWindowChan (BEST 24h)\n",
    "# ============================================================\n",
    "\n",
    "def generate_bsp_dataset_with_best24h(\n",
    "    code: str,\n",
    "    begin_time: str,\n",
    "    end_time: str,\n",
    "    lv_list: List[KL_TYPE],\n",
    "    data_src: DATA_SRC,\n",
    "    autype: AUTYPE,\n",
    "    config: CChanConfig,\n",
    "    max_klines: int = 1000\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate BSP feature dataframe with BEST-24h labels, but now using ChanStreamer.\n",
    "\n",
    "    - ChanStreamer feeds K-lines one by one into a single CChan instance.\n",
    "    - At each step, we collect *new* BSPs.\n",
    "    - After full period, we compute BEST-within-24h profit_target_pct.\n",
    "    \"\"\"\n",
    "    print(\"[ðŸ§ª] Generating BSP dataset via ChanStreamer (streaming)...\")\n",
    "    lv = lv_list[0]\n",
    "\n",
    "    # Time window bars for BEST 24h\n",
    "    time_windows = {\n",
    "        KL_TYPE.K_5M: 288,   # 5m * 288 = 24h\n",
    "        KL_TYPE.K_15M: 96,\n",
    "        KL_TYPE.K_30M: 48,\n",
    "        KL_TYPE.K_60M: 24,\n",
    "        KL_TYPE.K_DAY: 1,\n",
    "    }\n",
    "    time_window = time_windows.get(lv, 288)\n",
    "    print(f\"[â°] Time window: {time_window} bars (~24h for {lv.name})\")\n",
    "\n",
    "    # --- 1) Build streamer ---\n",
    "    streamer = ChanStreamer(\n",
    "        code=code,\n",
    "        begin_time=begin_time,\n",
    "        end_time=end_time,\n",
    "        data_src=data_src,\n",
    "        lv=lv,\n",
    "        config=config,\n",
    "        autype=autype,\n",
    "        max_klines=max_klines,   # sliding buffer inside streamer\n",
    "    )\n",
    "\n",
    "    from datetime import datetime as _dt\n",
    "    last_print = _dt.now()\n",
    "\n",
    "    # --- 2) Stream K-lines and collect BSPs as they appear ---\n",
    "    for idx, klu, new_bsp_list in streamer.stream_from_source():\n",
    "        # Optional progress print (similar style to your SlidingWindowChan logs)\n",
    "        now = _dt.now()\n",
    "        if idx % 100 == 0 or (now - last_print).total_seconds() > 5:\n",
    "            stats = streamer.get_stats()\n",
    "            print(\n",
    "                f\"[ðŸ“ˆ] Snapshot {idx}: \"\n",
    "                f\"{stats['unique_bsp_count']} BSP collected, \"\n",
    "                f\"buffer={stats['buffer_size']}\"\n",
    "            )\n",
    "            last_print = now\n",
    "\n",
    "        # If you want to inspect new BSPs in real time, you could:\n",
    "        # for bsp in new_bsp_list:\n",
    "        #     print(\"New BSP:\", bsp[\"timestamp\"], bsp[\"bsp_type\"], bsp[\"direction\"])\n",
    "\n",
    "    # --- 3) After streaming, get full BSP list ---\n",
    "    all_bsp_data = streamer.get_all_historical_bsp()\n",
    "    print(f\"[âœ…] Streaming complete, got {len(all_bsp_data)} unique BSPs\")\n",
    "\n",
    "    if not all_bsp_data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- 4) Profit labels (BEST within 24h) ---\n",
    "    profit_targets = calculate_profit_targets_best_within_24h(\n",
    "        all_bsp_data,\n",
    "        time_window_bars=time_window\n",
    "    )\n",
    "\n",
    "    # Attach labels into BSP rows\n",
    "    for row in all_bsp_data:\n",
    "        idx = row['klu_idx']\n",
    "        if idx in profit_targets:\n",
    "            row.update(profit_targets[idx])\n",
    "        else:\n",
    "            row['profit_target_pct'] = None\n",
    "            row['profit_target_distance'] = None\n",
    "            row['has_profit_target'] = 0\n",
    "            row['exit_type'] = None\n",
    "            row['exit_klu_idx'] = None\n",
    "            row['exit_price'] = None\n",
    "\n",
    "    # --- 5) Build DataFrame, add timestamp/date, and prep ML dataset ---\n",
    "    df = pd.DataFrame(all_bsp_data).sort_values('klu_idx').reset_index(drop=True)\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "    df = prepare_ml_dataset(df)\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# 8. Main function: Streaming-style Chan + XGBoost walk-forward\n",
    "# ============================================================\n",
    "\n",
    "def run_realtime_chan_xgb_trading_walkforward(\n",
    "    csv_path: str,\n",
    "    code: str = \"SPY\",\n",
    "    start_time: str = \"2022-01-01\",\n",
    "    end_time: str = \"2022-06-30\",\n",
    "    lv: KL_TYPE = KL_TYPE.K_5M,\n",
    "    chan_window_size: int = 1000,\n",
    "    train_days_for_model: int = 30,          # how many trading days to train\n",
    "    threshold_days_for_selection: int = 1,   # how many days to optimize thresholds\n",
    "    min_train_samples: int = 100,\n",
    "    min_valid_samples: int = 20,\n",
    "    initial_capital: float = 100_000.0,\n",
    "    position_size: float = 1.0,\n",
    "    transaction_fee_pct: float = 0.001,      # 0.1% per side\n",
    "    output_dir: str = \"./output/chan_xgb_streaming\",\n",
    "    plot_results: bool = True,\n",
    "    verbose: bool = True,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Integrated pipeline:\n",
    "    1) Use SlidingWindowChan to extract BSP features + profit_target_pct (BEST 24h).\n",
    "    2) Daily walk-forward:\n",
    "       - Train XGB on past `train_days_for_model` days.\n",
    "       - Optimize thresholds on previous `threshold_days_for_selection` days.\n",
    "       - Trade on current day using *only that day's BSPs*.\n",
    "       - Apply transaction fee on each trade.\n",
    "    3) Compare strategy equity vs Buy & Hold (from csv_path).\n",
    "\n",
    "    Returns a dict with:\n",
    "        'daily_results_df', 'trades_df', 'bsp_df', 'bh_df'\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Realtime Chan + XGBoost Streaming Walk-Forward\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Code: {code}\")\n",
    "    print(f\"Period: {start_time} â†’ {end_time}\")\n",
    "    print(f\"Train days: {train_days_for_model}, Threshold days: {threshold_days_for_selection}\")\n",
    "    print(f\"Initial capital: {initial_capital}, Position size: {position_size*100:.0f}%\")\n",
    "    print(f\"Transaction fee per side: {transaction_fee_pct*100:.3f}%\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Chan config (same style as your testing script)\n",
    "    config = CChanConfig({\n",
    "        \"cal_demark\": True,\n",
    "        \"cal_kdj\": True,\n",
    "        \"cal_dmi\": True,\n",
    "        \"cal_rsi\": True,\n",
    "        \"cal_rsl\": True,\n",
    "        \"cal_demand_index\": True,\n",
    "        \"cal_adline\": True,\n",
    "        \"cal_bb_vals\": True,\n",
    "        \"cal_kc_vals\": True,\n",
    "        \"cal_starc_vals\": True,\n",
    "        \"bi_strict\": True,\n",
    "        \"trigger_step\": True,\n",
    "        \"skip_step\": 0,\n",
    "        \"divergence_rate\": float(\"inf\"),\n",
    "        \"bsp2_follow_1\": True,\n",
    "        \"bsp3_follow_1\": False,\n",
    "        \"min_zs_cnt\": 0,\n",
    "        \"bs1_peak\": False,\n",
    "        \"macd_algo\": \"peak\",\n",
    "        \"bs_type\": '1,2,3a,1p,2s,3b',\n",
    "        \"print_warning\": False,\n",
    "        \"zs_algo\": \"normal\",\n",
    "    })\n",
    "\n",
    "    # 1) Generate BSP dataset with BEST 24h labels\n",
    "    bsp_df = generate_bsp_dataset_with_best24h(\n",
    "        code=code,\n",
    "        begin_time=start_time,\n",
    "        end_time=end_time,\n",
    "        lv_list=[lv],\n",
    "        data_src=DATA_SRC.CSV,\n",
    "        autype=AUTYPE.QFQ,\n",
    "        config=config,\n",
    "        max_klines=chan_window_size\n",
    "    )\n",
    "\n",
    "    if bsp_df.empty:\n",
    "        print(\"[âŒ] No BSP data generated. Aborting.\")\n",
    "        return {}\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[ðŸ“Š] BSP dataset shape: {bsp_df.shape}\")\n",
    "        print(f\"      Date range: {bsp_df['timestamp'].min()} â†’ {bsp_df['timestamp'].max()}\")\n",
    "\n",
    "    # Keep only BSPs with a known profit target for training\n",
    "    bsp_valid = bsp_df[bsp_df['has_profit_target'] == 1].copy()\n",
    "    bsp_valid = bsp_valid.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # 2) Feature columns\n",
    "    feature_cols = get_feature_columns(bsp_valid, target_col=\"profit_target_pct\")\n",
    "    if verbose:\n",
    "        print(f\"[ðŸ§¬] Using {len(feature_cols)} feature columns.\")\n",
    "\n",
    "    # 3) Build trading-day index\n",
    "    trading_days = np.sort(bsp_valid['date'].unique())\n",
    "    if verbose:\n",
    "        print(f\"[ðŸ“…] Total BSP trading days: {len(trading_days)}\")\n",
    "\n",
    "    # Minimum days required before first trade:\n",
    "    min_days_needed = train_days_for_model + threshold_days_for_selection\n",
    "    if len(trading_days) <= min_days_needed:\n",
    "        print(\"[âŒ] Not enough trading days for specified train/threshold configuration.\")\n",
    "        return {}\n",
    "\n",
    "    daily_results = []\n",
    "    all_trades: List[Dict] = []\n",
    "\n",
    "    # 4) Walk-forward over days\n",
    "    for day_idx in range(min_days_needed, len(trading_days)):\n",
    "        test_day = trading_days[day_idx]\n",
    "        thr_start = day_idx - threshold_days_for_selection\n",
    "        train_end = thr_start\n",
    "        train_start = train_end - train_days_for_model\n",
    "\n",
    "        if train_start < 0:\n",
    "            continue\n",
    "\n",
    "        train_days = trading_days[train_start:train_end]\n",
    "        thr_days = trading_days[thr_start:day_idx]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"-\"*60)\n",
    "            print(f\"[WF] Test day: {test_day}\")\n",
    "            print(f\"     Train: {train_days[0]} â†’ {train_days[-1]} ({len(train_days)} days)\")\n",
    "            print(f\"     Threshold days: {thr_days[0]} â†’ {thr_days[-1]} ({len(thr_days)} days)\")\n",
    "\n",
    "        # Slice data\n",
    "        train_df = bsp_valid[bsp_valid['date'].isin(train_days)].copy()\n",
    "        thr_df = bsp_valid[bsp_valid['date'].isin(thr_days)].copy()\n",
    "        test_df = bsp_df[bsp_df['date'] == test_day].copy()  # IMPORTANT: test day can include BSPs w/o profit target\n",
    "\n",
    "        if len(train_df) < min_train_samples or len(thr_df) < min_valid_samples:\n",
    "            if verbose:\n",
    "                print(\"    [Skip] Not enough samples for train/threshold.\")\n",
    "            continue\n",
    "\n",
    "        # Split buy/sell for training (like your old code)\n",
    "        train_buy = train_df[train_df['direction'] == 'buy']\n",
    "        train_sell = train_df[train_df['direction'] == 'sell']\n",
    "\n",
    "        if len(train_buy) < 10 or len(train_sell) < 10:\n",
    "            if verbose:\n",
    "                print(\"    [Skip] Not enough buy/sell samples.\")\n",
    "            continue\n",
    "\n",
    "        X_train_buy = train_buy[feature_cols].values\n",
    "        y_train_buy = train_buy['profit_target_pct'].values\n",
    "\n",
    "        X_train_sell = train_sell[feature_cols].values\n",
    "        y_train_sell = train_sell['profit_target_pct'].values\n",
    "\n",
    "        # XGBoost models\n",
    "        model_params = {\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 150,\n",
    "            'subsample': 0.9,\n",
    "            'colsample_bytree': 0.9,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        buy_model = xgb.XGBRegressor(**model_params)\n",
    "        sell_model = xgb.XGBRegressor(**model_params)\n",
    "\n",
    "        buy_model.fit(X_train_buy, y_train_buy)\n",
    "        sell_model.fit(X_train_sell, y_train_sell)\n",
    "\n",
    "        # ðŸ”” ALERT: models built for this window\n",
    "        print(\n",
    "            f\"[MODEL] XGBoost models trained | \"\n",
    "            f\"train window: {train_days[0]} â†’ {train_days[-1]} | \"\n",
    "            f\"samples: buy={len(train_buy)}, sell={len(train_sell)}\"\n",
    "        )\n",
    "\n",
    "        # Threshold-optimization days (only BSPs with valid target)\n",
    "        thr_buy = thr_df[thr_df['direction'] == 'buy'].copy()\n",
    "        thr_sell = thr_df[thr_df['direction'] == 'sell'].copy()\n",
    "\n",
    "        if len(thr_buy) > 0:\n",
    "            thr_buy['predicted_profit_pct'] = buy_model.predict(thr_buy[feature_cols].values)\n",
    "        if len(thr_sell) > 0:\n",
    "            thr_sell['predicted_profit_pct'] = sell_model.predict(thr_sell[feature_cols].values)\n",
    "\n",
    "        thr_signals = pd.concat([thr_buy, thr_sell], ignore_index=True)\n",
    "        buy_th, sell_th = optimize_thresholds_with_fee(\n",
    "            thr_signals,\n",
    "            transaction_fee_pct=transaction_fee_pct\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"    [Thresholds] Buy={buy_th:.2f}%, Sell={sell_th:.2f}%\")\n",
    "\n",
    "        # TEST DAY predictions (we can trade even if has_profit_target == 0)\n",
    "        test_buy = test_df[test_df['direction'] == 'buy'].copy()\n",
    "        test_sell = test_df[test_df['direction'] == 'sell'].copy()\n",
    "\n",
    "        if len(test_buy) > 0:\n",
    "            test_buy['predicted_profit_pct'] = buy_model.predict(test_buy[feature_cols].values)\n",
    "        if len(test_sell) > 0:\n",
    "            test_sell['predicted_profit_pct'] = sell_model.predict(test_sell[feature_cols].values)\n",
    "\n",
    "        test_signals = pd.concat([test_buy, test_sell], ignore_index=True)\n",
    "        if len(test_signals) == 0:\n",
    "            if verbose:\n",
    "                print(\"    [Info] No BSP signals on test day.\")\n",
    "            continue\n",
    "\n",
    "        # Backtest test day\n",
    "        bt_res, trades = backtest_one_day_signals(\n",
    "            test_signals,\n",
    "            buy_threshold=buy_th,\n",
    "            sell_threshold=sell_th,\n",
    "            initial_capital=initial_capital,\n",
    "            position_size=position_size,\n",
    "            transaction_fee_pct=transaction_fee_pct,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        # Attach trade day to each trade\n",
    "        for t in trades:\n",
    "            t['test_date'] = test_day\n",
    "        all_trades.extend(trades)\n",
    "\n",
    "        # For evaluation vs label-based profit (optional)\n",
    "        # We only have profit_target_pct for those with has_profit_target == 1\n",
    "        # So we won't recompute label metrics here to keep it simple.\n",
    "\n",
    "        daily_results.append({\n",
    "            'date': test_day,\n",
    "            'train_start': train_days[0],\n",
    "            'train_end': train_days[-1],\n",
    "            'strategy_return': bt_res['return_pct'],\n",
    "            'signals': bt_res['signals'],\n",
    "            'trades': bt_res['trades'],\n",
    "            'win_rate': bt_res['win_rate'],\n",
    "            'buy_threshold': buy_th,\n",
    "            'sell_threshold': sell_th,\n",
    "        })\n",
    "\n",
    "    if len(daily_results) == 0:\n",
    "        print(\"[âŒ] No valid daily results. Check parameters / data.\")\n",
    "        return {}\n",
    "\n",
    "    daily_results_df = pd.DataFrame(daily_results).sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    # 5) Buy & Hold benchmark\n",
    "    bh_df = calc_buy_hold_daily(csv_path, start_time, end_time)\n",
    "    bh_map = bh_df.set_index('date')['cum_return_pct'].to_dict()\n",
    "\n",
    "    # Align B&H to strategy days\n",
    "    daily_results_df['buy_hold_cum_return'] = daily_results_df['date'].map(bh_map)\n",
    "    daily_results_df['strategy_cum_return'] = (1 + daily_results_df['strategy_return'] / 100).cumprod() * 100 - 100\n",
    "\n",
    "    # 6) Plot comparison\n",
    "    if plot_results:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        dates = pd.to_datetime(daily_results_df['date'])\n",
    "        plt.plot(dates, daily_results_df['strategy_cum_return'], label='Strategy', linewidth=2)\n",
    "        plt.plot(dates, daily_results_df['buy_hold_cum_return'], label='Buy & Hold (SPY)', linewidth=2)\n",
    "        plt.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "        plt.title(\"Cumulative Return: Strategy vs SPY Buy & Hold\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Cumulative Return (%)\")\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"strategy_vs_buyhold.png\"), dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    trades_df = pd.DataFrame(all_trades)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Streaming Chan + XGBoost Walk-Forward Complete\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Total test days: {len(daily_results_df)}\")\n",
    "        print(f\"Total completed trades: {len(trades_df)}\")\n",
    "        print(f\"Final strategy cumulative return: {daily_results_df['strategy_cum_return'].iloc[-1]:.2f}%\")\n",
    "        print(f\"Final SPY buy & hold cumulative return: {daily_results_df['buy_hold_cum_return'].iloc[-1]:.2f}%\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    # Save outputs\n",
    "    daily_results_df.to_csv(os.path.join(output_dir, \"daily_results.csv\"), index=False)\n",
    "    trades_df.to_csv(os.path.join(output_dir, \"trades.csv\"), index=False)\n",
    "    bsp_df.to_csv(os.path.join(output_dir, \"bsp_dataset_used.csv\"), index=False)\n",
    "\n",
    "    return {\n",
    "        \"daily_results_df\": daily_results_df,\n",
    "        \"trades_df\": trades_df,\n",
    "        \"bsp_df\": bsp_df,\n",
    "        \"bh_df\": bh_df,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50ffb46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Realtime Chan + XGBoost Streaming Walk-Forward\n",
      "================================================================================\n",
      "Code: SPY\n",
      "Period: 2022-01-01 â†’ 2022-03-31\n",
      "Train days: 30, Threshold days: 1\n",
      "Initial capital: 100000, Position size: 100%\n",
      "Transaction fee per side: 0.100%\n",
      "================================================================================\n",
      "[ðŸ§ª] Generating BSP dataset via SlidingWindowChan...\n",
      "[â°] Time window: 288 bars (~24h for K_5M)\n",
      "[ðŸ“¥] Loading K-lines from data source...\n",
      "CSV_API: Processed 1044283 lines, filtered to 11841 lines\n",
      "[âœ…] Loaded 11841 K-lines from source\n",
      "[ðŸªŸ] Starting sliding window processing (window size: 500)\n",
      "[ðŸ“Š] Total K-lines to process: 11841\n",
      "[ðŸ“ˆ] Snapshot 1: 0 BSP collected, window @ 0\n",
      "[ðŸ“ˆ] Snapshot 101: 0 BSP collected, window @ 0\n",
      "[ðŸ“ˆ] Snapshot 201: 0 BSP collected, window @ 0\n",
      "[ðŸ“ˆ] Snapshot 301: 13 BSP collected, window @ 0\n",
      "[ðŸ“ˆ] Snapshot 401: 32 BSP collected, window @ 0\n",
      "[ðŸ“ˆ] Snapshot 494: 49 BSP collected, window @ 0\n",
      "[ðŸ“ˆ] Snapshot 501: 50 BSP collected, window @ 1\n",
      "[ðŸ“ˆ] Snapshot 575: 73 BSP collected, window @ 75\n",
      "[ðŸ“ˆ] Snapshot 601: 77 BSP collected, window @ 101\n",
      "[ðŸ“ˆ] Snapshot 662: 93 BSP collected, window @ 162\n",
      "[ðŸ“ˆ] Snapshot 701: 104 BSP collected, window @ 201\n",
      "[ðŸ“ˆ] Snapshot 762: 121 BSP collected, window @ 262\n",
      "[ðŸ“ˆ] Snapshot 801: 125 BSP collected, window @ 301\n",
      "[ðŸ“ˆ] Snapshot 865: 147 BSP collected, window @ 365\n",
      "[ðŸ“ˆ] Snapshot 901: 157 BSP collected, window @ 401\n",
      "[ðŸ“ˆ] Snapshot 960: 168 BSP collected, window @ 460\n",
      "[ðŸ“ˆ] Snapshot 1001: 191 BSP collected, window @ 501\n",
      "[ðŸ“ˆ] Snapshot 1054: 209 BSP collected, window @ 554\n",
      "[ðŸ“ˆ] Snapshot 1101: 227 BSP collected, window @ 601\n",
      "[ðŸ“ˆ] Snapshot 1155: 241 BSP collected, window @ 655\n",
      "[ðŸ“ˆ] Snapshot 1201: 244 BSP collected, window @ 701\n",
      "[ðŸ“ˆ] Snapshot 1254: 252 BSP collected, window @ 754\n",
      "[ðŸ“ˆ] Snapshot 1301: 265 BSP collected, window @ 801\n",
      "[ðŸ“ˆ] Snapshot 1357: 277 BSP collected, window @ 857\n",
      "[ðŸ“ˆ] Snapshot 1401: 286 BSP collected, window @ 901\n",
      "[ðŸ“ˆ] Snapshot 1471: 298 BSP collected, window @ 971\n",
      "[ðŸ“ˆ] Snapshot 1501: 302 BSP collected, window @ 1001\n",
      "[ðŸ“ˆ] Snapshot 1569: 313 BSP collected, window @ 1069\n",
      "[ðŸ“ˆ] Snapshot 1601: 326 BSP collected, window @ 1101\n",
      "[ðŸ“ˆ] Snapshot 1661: 350 BSP collected, window @ 1161\n",
      "[ðŸ“ˆ] Snapshot 1701: 356 BSP collected, window @ 1201\n",
      "[ðŸ“ˆ] Snapshot 1755: 357 BSP collected, window @ 1255\n",
      "[ðŸ“ˆ] Snapshot 1801: 372 BSP collected, window @ 1301\n",
      "[ðŸ“ˆ] Snapshot 1845: 384 BSP collected, window @ 1345\n",
      "[ðŸ“ˆ] Snapshot 1900: 399 BSP collected, window @ 1400\n",
      "[ðŸ“ˆ] Snapshot 1901: 400 BSP collected, window @ 1401\n",
      "[ðŸ“ˆ] Snapshot 1954: 414 BSP collected, window @ 1454\n",
      "[ðŸ“ˆ] Snapshot 2001: 420 BSP collected, window @ 1501\n",
      "[ðŸ“ˆ] Snapshot 2051: 439 BSP collected, window @ 1551\n",
      "[ðŸ“ˆ] Snapshot 2101: 453 BSP collected, window @ 1601\n",
      "[ðŸ“ˆ] Snapshot 2159: 472 BSP collected, window @ 1659\n",
      "[ðŸ“ˆ] Snapshot 2201: 487 BSP collected, window @ 1701\n",
      "[ðŸ“ˆ] Snapshot 2248: 497 BSP collected, window @ 1748\n",
      "[ðŸ“ˆ] Snapshot 2293: 508 BSP collected, window @ 1793\n",
      "[ðŸ“ˆ] Snapshot 2301: 511 BSP collected, window @ 1801\n",
      "[ðŸ“ˆ] Snapshot 2345: 524 BSP collected, window @ 1845\n",
      "[ðŸ“ˆ] Snapshot 2386: 535 BSP collected, window @ 1886\n",
      "[ðŸ“ˆ] Snapshot 2401: 541 BSP collected, window @ 1901\n",
      "[ðŸ“ˆ] Snapshot 2440: 557 BSP collected, window @ 1940\n",
      "[ðŸ“ˆ] Snapshot 2480: 560 BSP collected, window @ 1980\n",
      "[ðŸ“ˆ] Snapshot 2501: 563 BSP collected, window @ 2001\n",
      "[ðŸ“ˆ] Snapshot 2542: 566 BSP collected, window @ 2042\n",
      "[ðŸ“ˆ] Snapshot 2583: 578 BSP collected, window @ 2083\n",
      "[ðŸ“ˆ] Snapshot 2601: 585 BSP collected, window @ 2101\n",
      "[ðŸ“ˆ] Snapshot 2640: 602 BSP collected, window @ 2140\n",
      "[ðŸ“ˆ] Snapshot 2683: 611 BSP collected, window @ 2183\n",
      "[ðŸ“ˆ] Snapshot 2701: 613 BSP collected, window @ 2201\n",
      "[ðŸ“ˆ] Snapshot 2748: 627 BSP collected, window @ 2248\n",
      "[ðŸ“ˆ] Snapshot 2795: 645 BSP collected, window @ 2295\n",
      "[ðŸ“ˆ] Snapshot 2801: 646 BSP collected, window @ 2301\n",
      "[ðŸ“ˆ] Snapshot 2857: 659 BSP collected, window @ 2357\n",
      "[ðŸ“ˆ] Snapshot 2901: 662 BSP collected, window @ 2401\n",
      "[ðŸ“ˆ] Snapshot 2946: 674 BSP collected, window @ 2446\n",
      "[ðŸ“ˆ] Snapshot 2986: 694 BSP collected, window @ 2486\n",
      "[ðŸ“ˆ] Snapshot 3001: 708 BSP collected, window @ 2501\n",
      "[ðŸ“ˆ] Snapshot 3043: 723 BSP collected, window @ 2543\n",
      "[ðŸ“ˆ] Snapshot 3091: 740 BSP collected, window @ 2591\n",
      "[ðŸ“ˆ] Snapshot 3101: 743 BSP collected, window @ 2601\n",
      "[ðŸ“ˆ] Snapshot 3152: 750 BSP collected, window @ 2652\n",
      "[ðŸ“ˆ] Snapshot 3196: 755 BSP collected, window @ 2696\n",
      "[ðŸ“ˆ] Snapshot 3201: 757 BSP collected, window @ 2701\n",
      "[ðŸ“ˆ] Snapshot 3242: 763 BSP collected, window @ 2742\n",
      "[ðŸ“ˆ] Snapshot 3282: 770 BSP collected, window @ 2782\n",
      "[ðŸ“ˆ] Snapshot 3301: 778 BSP collected, window @ 2801\n",
      "[ðŸ“ˆ] Snapshot 3341: 795 BSP collected, window @ 2841\n",
      "[ðŸ“ˆ] Snapshot 3379: 810 BSP collected, window @ 2879\n",
      "[ðŸ“ˆ] Snapshot 3401: 811 BSP collected, window @ 2901\n",
      "[ðŸ“ˆ] Snapshot 3447: 813 BSP collected, window @ 2947\n",
      "[ðŸ“ˆ] Snapshot 3497: 826 BSP collected, window @ 2997\n",
      "[ðŸ“ˆ] Snapshot 3501: 826 BSP collected, window @ 3001\n",
      "[ðŸ“ˆ] Snapshot 3555: 830 BSP collected, window @ 3055\n",
      "[ðŸ“ˆ] Snapshot 3600: 849 BSP collected, window @ 3100\n",
      "[ðŸ“ˆ] Snapshot 3601: 849 BSP collected, window @ 3101\n",
      "[ðŸ“ˆ] Snapshot 3654: 859 BSP collected, window @ 3154\n",
      "[ðŸ“ˆ] Snapshot 3701: 870 BSP collected, window @ 3201\n",
      "[ðŸ“ˆ] Snapshot 3751: 885 BSP collected, window @ 3251\n",
      "[ðŸ“ˆ] Snapshot 3801: 897 BSP collected, window @ 3301\n",
      "[ðŸ“ˆ] Snapshot 3855: 905 BSP collected, window @ 3355\n",
      "[ðŸ“ˆ] Snapshot 3901: 918 BSP collected, window @ 3401\n",
      "[ðŸ“ˆ] Snapshot 3959: 930 BSP collected, window @ 3459\n",
      "[ðŸ“ˆ] Snapshot 4001: 944 BSP collected, window @ 3501\n",
      "[ðŸ“ˆ] Snapshot 4054: 960 BSP collected, window @ 3554\n",
      "[ðŸ“ˆ] Snapshot 4101: 963 BSP collected, window @ 3601\n",
      "[ðŸ“ˆ] Snapshot 4163: 984 BSP collected, window @ 3663\n",
      "[ðŸ“ˆ] Snapshot 4201: 992 BSP collected, window @ 3701\n",
      "[ðŸ“ˆ] Snapshot 4258: 1005 BSP collected, window @ 3758\n",
      "[ðŸ“ˆ] Snapshot 4301: 1019 BSP collected, window @ 3801\n",
      "[ðŸ“ˆ] Snapshot 4354: 1029 BSP collected, window @ 3854\n",
      "[ðŸ“ˆ] Snapshot 4401: 1029 BSP collected, window @ 3901\n",
      "[ðŸ“ˆ] Snapshot 4461: 1040 BSP collected, window @ 3961\n",
      "[ðŸ“ˆ] Snapshot 4501: 1046 BSP collected, window @ 4001\n",
      "[ðŸ“ˆ] Snapshot 4541: 1054 BSP collected, window @ 4041\n",
      "[ðŸ“ˆ] Snapshot 4585: 1054 BSP collected, window @ 4085\n",
      "[ðŸ“ˆ] Snapshot 4601: 1060 BSP collected, window @ 4101\n",
      "[ðŸ“ˆ] Snapshot 4651: 1083 BSP collected, window @ 4151\n",
      "[ðŸ“ˆ] Snapshot 4696: 1089 BSP collected, window @ 4196\n",
      "[ðŸ“ˆ] Snapshot 4701: 1092 BSP collected, window @ 4201\n",
      "[ðŸ“ˆ] Snapshot 4752: 1104 BSP collected, window @ 4252\n",
      "[ðŸ“ˆ] Snapshot 4801: 1115 BSP collected, window @ 4301\n",
      "[ðŸ“ˆ] Snapshot 4844: 1126 BSP collected, window @ 4344\n",
      "[ðŸ“ˆ] Snapshot 4885: 1141 BSP collected, window @ 4385\n",
      "[ðŸ“ˆ] Snapshot 4901: 1145 BSP collected, window @ 4401\n",
      "[ðŸ“ˆ] Snapshot 4940: 1153 BSP collected, window @ 4440\n",
      "[ðŸ“ˆ] Snapshot 4981: 1160 BSP collected, window @ 4481\n",
      "[ðŸ“ˆ] Snapshot 5001: 1160 BSP collected, window @ 4501\n",
      "[ðŸ“ˆ] Snapshot 5042: 1169 BSP collected, window @ 4542\n",
      "[ðŸ“ˆ] Snapshot 5085: 1174 BSP collected, window @ 4585\n",
      "[ðŸ“ˆ] Snapshot 5101: 1178 BSP collected, window @ 4601\n",
      "[ðŸ“ˆ] Snapshot 5146: 1187 BSP collected, window @ 4646\n",
      "[ðŸ“ˆ] Snapshot 5195: 1189 BSP collected, window @ 4695\n",
      "[ðŸ“ˆ] Snapshot 5201: 1190 BSP collected, window @ 4701\n",
      "[ðŸ“ˆ] Snapshot 5243: 1206 BSP collected, window @ 4743\n",
      "[ðŸ“ˆ] Snapshot 5286: 1215 BSP collected, window @ 4786\n",
      "[ðŸ“ˆ] Snapshot 5301: 1227 BSP collected, window @ 4801\n",
      "[ðŸ“ˆ] Snapshot 5348: 1229 BSP collected, window @ 4848\n",
      "[ðŸ“ˆ] Snapshot 5393: 1239 BSP collected, window @ 4893\n",
      "[ðŸ“ˆ] Snapshot 5401: 1240 BSP collected, window @ 4901\n",
      "[ðŸ“ˆ] Snapshot 5441: 1249 BSP collected, window @ 4941\n",
      "[ðŸ“ˆ] Snapshot 5474: 1258 BSP collected, window @ 4974\n",
      "[ðŸ“ˆ] Snapshot 5501: 1261 BSP collected, window @ 5001\n",
      "[ðŸ“ˆ] Snapshot 5546: 1265 BSP collected, window @ 5046\n",
      "[ðŸ“ˆ] Snapshot 5590: 1275 BSP collected, window @ 5090\n",
      "[ðŸ“ˆ] Snapshot 5601: 1278 BSP collected, window @ 5101\n",
      "[ðŸ“ˆ] Snapshot 5639: 1289 BSP collected, window @ 5139\n",
      "[ðŸ“ˆ] Snapshot 5676: 1300 BSP collected, window @ 5176\n",
      "[ðŸ“ˆ] Snapshot 5701: 1300 BSP collected, window @ 5201\n",
      "[ðŸ“ˆ] Snapshot 5742: 1311 BSP collected, window @ 5242\n",
      "[ðŸ“ˆ] Snapshot 5784: 1318 BSP collected, window @ 5284\n",
      "[ðŸ“ˆ] Snapshot 5801: 1318 BSP collected, window @ 5301\n",
      "[ðŸ“ˆ] Snapshot 5841: 1329 BSP collected, window @ 5341\n",
      "[ðŸ“ˆ] Snapshot 5879: 1335 BSP collected, window @ 5379\n",
      "[ðŸ“ˆ] Snapshot 5901: 1335 BSP collected, window @ 5401\n",
      "[ðŸ“ˆ] Snapshot 5942: 1336 BSP collected, window @ 5442\n",
      "[ðŸ“ˆ] Snapshot 5985: 1341 BSP collected, window @ 5485\n",
      "[ðŸ“ˆ] Snapshot 6001: 1344 BSP collected, window @ 5501\n",
      "[ðŸ“ˆ] Snapshot 6043: 1348 BSP collected, window @ 5543\n",
      "[ðŸ“ˆ] Snapshot 6085: 1354 BSP collected, window @ 5585\n",
      "[ðŸ“ˆ] Snapshot 6101: 1357 BSP collected, window @ 5601\n",
      "[ðŸ“ˆ] Snapshot 6145: 1363 BSP collected, window @ 5645\n",
      "[ðŸ“ˆ] Snapshot 6182: 1367 BSP collected, window @ 5682\n",
      "[ðŸ“ˆ] Snapshot 6201: 1371 BSP collected, window @ 5701\n",
      "[ðŸ“ˆ] Snapshot 6240: 1384 BSP collected, window @ 5740\n",
      "[ðŸ“ˆ] Snapshot 6278: 1389 BSP collected, window @ 5778\n",
      "[ðŸ“ˆ] Snapshot 6301: 1393 BSP collected, window @ 5801\n",
      "[ðŸ“ˆ] Snapshot 6344: 1393 BSP collected, window @ 5844\n",
      "[ðŸ“ˆ] Snapshot 6392: 1399 BSP collected, window @ 5892\n",
      "[ðŸ“ˆ] Snapshot 6401: 1399 BSP collected, window @ 5901\n",
      "[ðŸ“ˆ] Snapshot 6438: 1407 BSP collected, window @ 5938\n",
      "[ðŸ“ˆ] Snapshot 6478: 1407 BSP collected, window @ 5978\n",
      "[ðŸ“ˆ] Snapshot 6501: 1409 BSP collected, window @ 6001\n",
      "[ðŸ“ˆ] Snapshot 6541: 1416 BSP collected, window @ 6041\n",
      "[ðŸ“ˆ] Snapshot 6583: 1427 BSP collected, window @ 6083\n",
      "[ðŸ“ˆ] Snapshot 6601: 1436 BSP collected, window @ 6101\n",
      "[ðŸ“ˆ] Snapshot 6643: 1452 BSP collected, window @ 6143\n",
      "[ðŸ“ˆ] Snapshot 6683: 1462 BSP collected, window @ 6183\n",
      "[ðŸ“ˆ] Snapshot 6701: 1463 BSP collected, window @ 6201\n",
      "[ðŸ“ˆ] Snapshot 6743: 1468 BSP collected, window @ 6243\n",
      "[ðŸ“ˆ] Snapshot 6780: 1486 BSP collected, window @ 6280\n",
      "[ðŸ“ˆ] Snapshot 6801: 1497 BSP collected, window @ 6301\n",
      "[ðŸ“ˆ] Snapshot 6834: 1507 BSP collected, window @ 6334\n",
      "[ðŸ“ˆ] Snapshot 6874: 1518 BSP collected, window @ 6374\n",
      "[ðŸ“ˆ] Snapshot 6901: 1525 BSP collected, window @ 6401\n",
      "[ðŸ“ˆ] Snapshot 6944: 1530 BSP collected, window @ 6444\n",
      "[ðŸ“ˆ] Snapshot 6986: 1535 BSP collected, window @ 6486\n",
      "[ðŸ“ˆ] Snapshot 7001: 1535 BSP collected, window @ 6501\n",
      "[ðŸ“ˆ] Snapshot 7049: 1538 BSP collected, window @ 6549\n",
      "[ðŸ“ˆ] Snapshot 7088: 1545 BSP collected, window @ 6588\n",
      "[ðŸ“ˆ] Snapshot 7101: 1545 BSP collected, window @ 6601\n",
      "[ðŸ“ˆ] Snapshot 7139: 1556 BSP collected, window @ 6639\n",
      "[ðŸ“ˆ] Snapshot 7182: 1574 BSP collected, window @ 6682\n",
      "[ðŸ“ˆ] Snapshot 7201: 1576 BSP collected, window @ 6701\n",
      "[ðŸ“ˆ] Snapshot 7252: 1592 BSP collected, window @ 6752\n",
      "[ðŸ“ˆ] Snapshot 7301: 1594 BSP collected, window @ 6801\n",
      "[ðŸ“ˆ] Snapshot 7363: 1607 BSP collected, window @ 6863\n",
      "[ðŸ“ˆ] Snapshot 7401: 1617 BSP collected, window @ 6901\n",
      "[ðŸ“ˆ] Snapshot 7443: 1627 BSP collected, window @ 6943\n",
      "[ðŸ“ˆ] Snapshot 7484: 1642 BSP collected, window @ 6984\n",
      "[ðŸ“ˆ] Snapshot 7501: 1644 BSP collected, window @ 7001\n",
      "[ðŸ“ˆ] Snapshot 7542: 1655 BSP collected, window @ 7042\n",
      "[ðŸ“ˆ] Snapshot 7583: 1660 BSP collected, window @ 7083\n",
      "[ðŸ“ˆ] Snapshot 7601: 1663 BSP collected, window @ 7101\n",
      "[ðŸ“ˆ] Snapshot 7645: 1665 BSP collected, window @ 7145\n",
      "[ðŸ“ˆ] Snapshot 7688: 1680 BSP collected, window @ 7188\n",
      "[ðŸ“ˆ] Snapshot 7701: 1684 BSP collected, window @ 7201\n",
      "[ðŸ“ˆ] Snapshot 7742: 1689 BSP collected, window @ 7242\n",
      "[ðŸ“ˆ] Snapshot 7774: 1691 BSP collected, window @ 7274\n",
      "[ðŸ“ˆ] Snapshot 7801: 1699 BSP collected, window @ 7301\n",
      "[ðŸ“ˆ] Snapshot 7834: 1701 BSP collected, window @ 7334\n",
      "[ðŸ“ˆ] Snapshot 7868: 1709 BSP collected, window @ 7368\n",
      "[ðŸ“ˆ] Snapshot 7900: 1720 BSP collected, window @ 7400\n",
      "[ðŸ“ˆ] Snapshot 7901: 1720 BSP collected, window @ 7401\n",
      "[ðŸ“ˆ] Snapshot 7931: 1729 BSP collected, window @ 7431\n",
      "[ðŸ“ˆ] Snapshot 7961: 1729 BSP collected, window @ 7461\n",
      "[ðŸ“ˆ] Snapshot 7994: 1733 BSP collected, window @ 7494\n",
      "[ðŸ“ˆ] Snapshot 8001: 1736 BSP collected, window @ 7501\n",
      "[ðŸ“ˆ] Snapshot 8033: 1750 BSP collected, window @ 7533\n",
      "[ðŸ“ˆ] Snapshot 8065: 1759 BSP collected, window @ 7565\n",
      "[ðŸ“ˆ] Snapshot 8098: 1769 BSP collected, window @ 7598\n",
      "[ðŸ“ˆ] Snapshot 8101: 1771 BSP collected, window @ 7601\n",
      "[ðŸ“ˆ] Snapshot 8130: 1782 BSP collected, window @ 7630\n",
      "[ðŸ“ˆ] Snapshot 8160: 1783 BSP collected, window @ 7660\n",
      "[ðŸ“ˆ] Snapshot 8193: 1785 BSP collected, window @ 7693\n",
      "[ðŸ“ˆ] Snapshot 8201: 1785 BSP collected, window @ 7701\n",
      "[ðŸ“ˆ] Snapshot 8232: 1791 BSP collected, window @ 7732\n",
      "[ðŸ“ˆ] Snapshot 8261: 1794 BSP collected, window @ 7761\n",
      "[ðŸ“ˆ] Snapshot 8293: 1805 BSP collected, window @ 7793\n",
      "[ðŸ“ˆ] Snapshot 8301: 1806 BSP collected, window @ 7801\n",
      "[ðŸ“ˆ] Snapshot 8332: 1814 BSP collected, window @ 7832\n",
      "[ðŸ“ˆ] Snapshot 8363: 1826 BSP collected, window @ 7863\n",
      "[ðŸ“ˆ] Snapshot 8398: 1828 BSP collected, window @ 7898\n",
      "[ðŸ“ˆ] Snapshot 8401: 1829 BSP collected, window @ 7901\n",
      "[ðŸ“ˆ] Snapshot 8435: 1831 BSP collected, window @ 7935\n",
      "[ðŸ“ˆ] Snapshot 8471: 1840 BSP collected, window @ 7971\n",
      "[ðŸ“ˆ] Snapshot 8501: 1848 BSP collected, window @ 8001\n",
      "[ðŸ“ˆ] Snapshot 8535: 1866 BSP collected, window @ 8035\n",
      "[ðŸ“ˆ] Snapshot 8569: 1882 BSP collected, window @ 8069\n",
      "[ðŸ“ˆ] Snapshot 8600: 1898 BSP collected, window @ 8100\n",
      "[ðŸ“ˆ] Snapshot 8601: 1899 BSP collected, window @ 8101\n",
      "[ðŸ“ˆ] Snapshot 8635: 1908 BSP collected, window @ 8135\n",
      "[ðŸ“ˆ] Snapshot 8667: 1915 BSP collected, window @ 8167\n",
      "[ðŸ“ˆ] Snapshot 8697: 1923 BSP collected, window @ 8197\n",
      "[ðŸ“ˆ] Snapshot 8701: 1923 BSP collected, window @ 8201\n",
      "[ðŸ“ˆ] Snapshot 8732: 1933 BSP collected, window @ 8232\n",
      "[ðŸ“ˆ] Snapshot 8768: 1933 BSP collected, window @ 8268\n",
      "[ðŸ“ˆ] Snapshot 8801: 1933 BSP collected, window @ 8301\n",
      "[ðŸ“ˆ] Snapshot 8837: 1933 BSP collected, window @ 8337\n",
      "[ðŸ“ˆ] Snapshot 8867: 1941 BSP collected, window @ 8367\n",
      "[ðŸ“ˆ] Snapshot 8894: 1954 BSP collected, window @ 8394\n",
      "[ðŸ“ˆ] Snapshot 8901: 1957 BSP collected, window @ 8401\n",
      "[ðŸ“ˆ] Snapshot 8929: 1971 BSP collected, window @ 8429\n",
      "[ðŸ“ˆ] Snapshot 8954: 1972 BSP collected, window @ 8454\n",
      "[ðŸ“ˆ] Snapshot 8982: 1976 BSP collected, window @ 8482\n",
      "[ðŸ“ˆ] Snapshot 9001: 1982 BSP collected, window @ 8501\n",
      "[ðŸ“ˆ] Snapshot 9034: 1983 BSP collected, window @ 8534\n",
      "[ðŸ“ˆ] Snapshot 9069: 1983 BSP collected, window @ 8569\n",
      "[ðŸ“ˆ] Snapshot 9101: 1989 BSP collected, window @ 8601\n",
      "[ðŸ“ˆ] Snapshot 9132: 2001 BSP collected, window @ 8632\n",
      "[ðŸ“ˆ] Snapshot 9167: 2001 BSP collected, window @ 8667\n",
      "[ðŸ“ˆ] Snapshot 9199: 2013 BSP collected, window @ 8699\n",
      "[ðŸ“ˆ] Snapshot 9201: 2014 BSP collected, window @ 8701\n",
      "[ðŸ“ˆ] Snapshot 9243: 2028 BSP collected, window @ 8743\n",
      "[ðŸ“ˆ] Snapshot 9280: 2047 BSP collected, window @ 8780\n",
      "[ðŸ“ˆ] Snapshot 9301: 2056 BSP collected, window @ 8801\n",
      "[ðŸ“ˆ] Snapshot 9334: 2058 BSP collected, window @ 8834\n",
      "[ðŸ“ˆ] Snapshot 9369: 2065 BSP collected, window @ 8869\n",
      "[ðŸ“ˆ] Snapshot 9401: 2069 BSP collected, window @ 8901\n",
      "[ðŸ“ˆ] Snapshot 9437: 2075 BSP collected, window @ 8937\n",
      "[ðŸ“ˆ] Snapshot 9470: 2086 BSP collected, window @ 8970\n",
      "[ðŸ“ˆ] Snapshot 9501: 2094 BSP collected, window @ 9001\n",
      "[ðŸ“ˆ] Snapshot 9535: 2095 BSP collected, window @ 9035\n",
      "[ðŸ“ˆ] Snapshot 9572: 2102 BSP collected, window @ 9072\n",
      "[ðŸ“ˆ] Snapshot 9601: 2102 BSP collected, window @ 9101\n",
      "[ðŸ“ˆ] Snapshot 9640: 2106 BSP collected, window @ 9140\n",
      "[ðŸ“ˆ] Snapshot 9681: 2107 BSP collected, window @ 9181\n",
      "[ðŸ“ˆ] Snapshot 9701: 2123 BSP collected, window @ 9201\n",
      "[ðŸ“ˆ] Snapshot 9740: 2133 BSP collected, window @ 9240\n",
      "[ðŸ“ˆ] Snapshot 9788: 2144 BSP collected, window @ 9288\n",
      "[ðŸ“ˆ] Snapshot 9801: 2146 BSP collected, window @ 9301\n",
      "[ðŸ“ˆ] Snapshot 9847: 2164 BSP collected, window @ 9347\n",
      "[ðŸ“ˆ] Snapshot 9881: 2179 BSP collected, window @ 9381\n",
      "[ðŸ“ˆ] Snapshot 9901: 2183 BSP collected, window @ 9401\n",
      "[ðŸ“ˆ] Snapshot 9935: 2184 BSP collected, window @ 9435\n",
      "[ðŸ“ˆ] Snapshot 9966: 2192 BSP collected, window @ 9466\n",
      "[ðŸ“ˆ] Snapshot 9995: 2197 BSP collected, window @ 9495\n",
      "[ðŸ“ˆ] Snapshot 10001: 2197 BSP collected, window @ 9501\n",
      "[ðŸ“ˆ] Snapshot 10028: 2201 BSP collected, window @ 9528\n",
      "[ðŸ“ˆ] Snapshot 10056: 2212 BSP collected, window @ 9556\n",
      "[ðŸ“ˆ] Snapshot 10081: 2223 BSP collected, window @ 9581\n",
      "[ðŸ“ˆ] Snapshot 10101: 2229 BSP collected, window @ 9601\n",
      "[ðŸ“ˆ] Snapshot 10129: 2233 BSP collected, window @ 9629\n",
      "[ðŸ“ˆ] Snapshot 10156: 2234 BSP collected, window @ 9656\n",
      "[ðŸ“ˆ] Snapshot 10180: 2236 BSP collected, window @ 9680\n",
      "[ðŸ“ˆ] Snapshot 10201: 2237 BSP collected, window @ 9701\n",
      "[ðŸ“ˆ] Snapshot 10230: 2240 BSP collected, window @ 9730\n",
      "[ðŸ“ˆ] Snapshot 10258: 2251 BSP collected, window @ 9758\n",
      "[ðŸ“ˆ] Snapshot 10289: 2252 BSP collected, window @ 9789\n",
      "[ðŸ“ˆ] Snapshot 10301: 2259 BSP collected, window @ 9801\n",
      "[ðŸ“ˆ] Snapshot 10331: 2272 BSP collected, window @ 9831\n",
      "[ðŸ“ˆ] Snapshot 10359: 2274 BSP collected, window @ 9859\n",
      "[ðŸ“ˆ] Snapshot 10389: 2281 BSP collected, window @ 9889\n",
      "[ðŸ“ˆ] Snapshot 10401: 2288 BSP collected, window @ 9901\n",
      "[ðŸ“ˆ] Snapshot 10428: 2292 BSP collected, window @ 9928\n",
      "[ðŸ“ˆ] Snapshot 10455: 2298 BSP collected, window @ 9955\n",
      "[ðŸ“ˆ] Snapshot 10488: 2301 BSP collected, window @ 9988\n",
      "[ðŸ“ˆ] Snapshot 10501: 2301 BSP collected, window @ 10001\n",
      "[ðŸ“ˆ] Snapshot 10534: 2308 BSP collected, window @ 10034\n",
      "[ðŸ“ˆ] Snapshot 10563: 2313 BSP collected, window @ 10063\n",
      "[ðŸ“ˆ] Snapshot 10589: 2319 BSP collected, window @ 10089\n",
      "[ðŸ“ˆ] Snapshot 10601: 2319 BSP collected, window @ 10101\n",
      "[ðŸ“ˆ] Snapshot 10631: 2326 BSP collected, window @ 10131\n",
      "[ðŸ“ˆ] Snapshot 10660: 2336 BSP collected, window @ 10160\n",
      "[ðŸ“ˆ] Snapshot 10687: 2337 BSP collected, window @ 10187\n",
      "[ðŸ“ˆ] Snapshot 10701: 2338 BSP collected, window @ 10201\n",
      "[ðŸ“ˆ] Snapshot 10739: 2347 BSP collected, window @ 10239\n",
      "[ðŸ“ˆ] Snapshot 10771: 2353 BSP collected, window @ 10271\n",
      "[ðŸ“ˆ] Snapshot 10797: 2357 BSP collected, window @ 10297\n",
      "[ðŸ“ˆ] Snapshot 10801: 2360 BSP collected, window @ 10301\n",
      "[ðŸ“ˆ] Snapshot 10826: 2372 BSP collected, window @ 10326\n",
      "[ðŸ“ˆ] Snapshot 10852: 2384 BSP collected, window @ 10352\n",
      "[ðŸ“ˆ] Snapshot 10878: 2384 BSP collected, window @ 10378\n",
      "[ðŸ“ˆ] Snapshot 10900: 2388 BSP collected, window @ 10400\n",
      "[ðŸ“ˆ] Snapshot 10901: 2388 BSP collected, window @ 10401\n",
      "[ðŸ“ˆ] Snapshot 10926: 2389 BSP collected, window @ 10426\n",
      "[ðŸ“ˆ] Snapshot 10955: 2391 BSP collected, window @ 10455\n",
      "[ðŸ“ˆ] Snapshot 10983: 2395 BSP collected, window @ 10483\n",
      "[ðŸ“ˆ] Snapshot 11001: 2399 BSP collected, window @ 10501\n",
      "[ðŸ“ˆ] Snapshot 11030: 2411 BSP collected, window @ 10530\n",
      "[ðŸ“ˆ] Snapshot 11051: 2413 BSP collected, window @ 10551\n",
      "[ðŸ“ˆ] Snapshot 11076: 2415 BSP collected, window @ 10576\n",
      "[ðŸ“ˆ] Snapshot 11101: 2419 BSP collected, window @ 10601\n",
      "[ðŸ“ˆ] Snapshot 11137: 2431 BSP collected, window @ 10637\n",
      "[ðŸ“ˆ] Snapshot 11178: 2440 BSP collected, window @ 10678\n",
      "[ðŸ“ˆ] Snapshot 11201: 2452 BSP collected, window @ 10701\n",
      "[ðŸ“ˆ] Snapshot 11231: 2456 BSP collected, window @ 10731\n",
      "[ðŸ“ˆ] Snapshot 11266: 2456 BSP collected, window @ 10766\n",
      "[ðŸ“ˆ] Snapshot 11301: 2457 BSP collected, window @ 10801\n",
      "[ðŸ“ˆ] Snapshot 11332: 2461 BSP collected, window @ 10832\n",
      "[ðŸ“ˆ] Snapshot 11358: 2470 BSP collected, window @ 10858\n",
      "[ðŸ“ˆ] Snapshot 11377: 2476 BSP collected, window @ 10877\n",
      "[ðŸ“ˆ] Snapshot 11397: 2483 BSP collected, window @ 10897\n",
      "[ðŸ“ˆ] Snapshot 11401: 2487 BSP collected, window @ 10901\n",
      "[ðŸ“ˆ] Snapshot 11422: 2496 BSP collected, window @ 10922\n",
      "[ðŸ“ˆ] Snapshot 11441: 2497 BSP collected, window @ 10941\n",
      "[ðŸ“ˆ] Snapshot 11464: 2503 BSP collected, window @ 10964\n",
      "[ðŸ“ˆ] Snapshot 11489: 2504 BSP collected, window @ 10989\n",
      "[ðŸ“ˆ] Snapshot 11501: 2504 BSP collected, window @ 11001\n",
      "[ðŸ“ˆ] Snapshot 11525: 2511 BSP collected, window @ 11025\n",
      "[ðŸ“ˆ] Snapshot 11547: 2522 BSP collected, window @ 11047\n",
      "[ðŸ“ˆ] Snapshot 11568: 2525 BSP collected, window @ 11068\n",
      "[ðŸ“ˆ] Snapshot 11597: 2543 BSP collected, window @ 11097\n",
      "[ðŸ“ˆ] Snapshot 11601: 2544 BSP collected, window @ 11101\n",
      "[ðŸ“ˆ] Snapshot 11627: 2545 BSP collected, window @ 11127\n",
      "[ðŸ“ˆ] Snapshot 11659: 2545 BSP collected, window @ 11159\n",
      "[ðŸ“ˆ] Snapshot 11701: 2553 BSP collected, window @ 11201\n",
      "[ðŸ“ˆ] Snapshot 11737: 2560 BSP collected, window @ 11237\n",
      "[ðŸ“ˆ] Snapshot 11774: 2576 BSP collected, window @ 11274\n",
      "[ðŸ“ˆ] Snapshot 11801: 2587 BSP collected, window @ 11301\n",
      "[ðŸ“ˆ] Snapshot 11838: 2587 BSP collected, window @ 11338\n",
      "[âœ…] Sliding window complete, got 2587 unique BSPs\n",
      "[ðŸŽ¯] STEP 2: Calculating profit targets using BEST within 288 bars (~24h)...\n",
      "[ðŸ“Š] Profit Target Summary (BEST within 24h):\n",
      "  Total BS points: 2587\n",
      "  Points with targets: 2349 (90.8%)\n",
      "  Exit types:\n",
      "    - Best within 24h: 2349 (100.0%)\n",
      "    - Fallback (next reverse): 0 (0.0%)\n",
      "  Average profit: 1.30%\n",
      "  Median profit: 1.06%\n",
      "  Best profit: 6.68%\n",
      "  Worst result: -2.10%\n",
      "  Average distance: 164.2 bars\n",
      "  Profitable trades: 2126/2349 (90.5%)\n",
      "[ðŸ”§] Preparing final ML dataset...\n",
      "[âœ…] Dataset prepared with 2587 samples and 80 features\n",
      "[ðŸ“Š] BSP dataset shape: (2587, 80)\n",
      "      Date range: 2022-01-04 05:10:00 â†’ 2022-03-31 15:55:00\n",
      "[ðŸ§¬] Using 64 feature columns.\n",
      "[ðŸ“…] Total BSP trading days: 60\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-02-17\n",
      "     Train: 2022-01-04 â†’ 2022-02-15 (30 days)\n",
      "     Threshold days: 2022-02-16 â†’ 2022-02-16 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-04 â†’ 2022-02-15 | samples: buy=575, sell=764\n",
      "    [Thresholds] Buy=2.00%, Sell=1.75%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-02-18\n",
      "     Train: 2022-01-05 â†’ 2022-02-16 (30 days)\n",
      "     Threshold days: 2022-02-17 â†’ 2022-02-17 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-05 â†’ 2022-02-16 | samples: buy=586, sell=747\n",
      "    [Thresholds] Buy=2.00%, Sell=1.88%\n",
      "[TRADE] BUY confirmed at 2022-02-18 08:30:00 | close price = 436.4400\n",
      "[TRADE] SELL confirmed at 2022-02-18 15:00:00 | close price = 436.3300 | trade return = -0.13%\n",
      "    Day summary: trades=1, win_rate=0.0%, day_return=-0.23%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-02-22\n",
      "     Train: 2022-01-06 â†’ 2022-02-17 (30 days)\n",
      "     Threshold days: 2022-02-18 â†’ 2022-02-18 (1 days)\n",
      "    [Skip] Not enough samples for train/threshold.\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-02-23\n",
      "     Train: 2022-01-07 â†’ 2022-02-18 (30 days)\n",
      "     Threshold days: 2022-02-22 â†’ 2022-02-22 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-07 â†’ 2022-02-18 | samples: buy=570, sell=713\n",
      "    [Thresholds] Buy=3.00%, Sell=-0.50%\n",
      "[TRADE] BUY confirmed at 2022-02-23 10:05:00 | close price = 429.7600\n",
      "[TRADE] SELL confirmed at 2022-02-23 11:50:00 | close price = 428.6299 | trade return = -0.36%\n",
      "[TRADE] BUY confirmed at 2022-02-23 12:55:00 | close price = 428.0200\n",
      "[TRADE] SELL confirmed at 2022-02-23 19:55:00 | close price = 418.8500 | trade return = -2.24%\n",
      "    Day summary: trades=2, win_rate=0.0%, day_return=-2.79%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-02-24\n",
      "     Train: 2022-01-10 â†’ 2022-02-22 (30 days)\n",
      "     Threshold days: 2022-02-23 â†’ 2022-02-23 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-10 â†’ 2022-02-22 | samples: buy=582, sell=714\n",
      "    [Thresholds] Buy=3.00%, Sell=-0.50%\n",
      "[TRADE] BUY confirmed at 2022-02-24 04:00:00 | close price = 414.5100\n",
      "[TRADE] SELL confirmed at 2022-02-24 15:50:00 | close price = 428.5100 | trade return = 3.27%\n",
      "[TRADE] BUY confirmed at 2022-02-24 18:20:00 | close price = 426.1700\n",
      "[TRADE] SELL confirmed at 2022-02-24 19:25:00 | close price = 427.2500 | trade return = 0.15%\n",
      "[TRADE] BUY confirmed at 2022-02-24 19:50:00 | close price = 425.9000\n",
      "[TRADE] SELL confirmed at 2022-02-24 19:50:00 | close price = 425.9000 | trade return = -0.10%\n",
      "    Day summary: trades=3, win_rate=66.7%, day_return=3.02%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-02-25\n",
      "     Train: 2022-01-11 â†’ 2022-02-23 (30 days)\n",
      "     Threshold days: 2022-02-24 â†’ 2022-02-24 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-11 â†’ 2022-02-23 | samples: buy=583, sell=701\n",
      "    [Thresholds] Buy=-0.50%, Sell=3.00%\n",
      "[TRADE] BUY confirmed at 2022-02-25 04:00:00 | close price = 423.3100\n",
      "[TRADE] SELL confirmed at 2022-02-25 07:55:00 | close price = 429.1700 | trade return = 1.28%\n",
      "[TRADE] BUY confirmed at 2022-02-25 09:10:00 | close price = 429.4000\n",
      "[TRADE] SELL confirmed at 2022-02-25 19:55:00 | close price = 437.7000 | trade return = 1.83%\n",
      "    Day summary: trades=2, win_rate=100.0%, day_return=2.93%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-02-28\n",
      "     Train: 2022-01-12 â†’ 2022-02-24 (30 days)\n",
      "     Threshold days: 2022-02-25 â†’ 2022-02-25 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-12 â†’ 2022-02-24 | samples: buy=596, sell=670\n",
      "    [Thresholds] Buy=1.75%, Sell=3.00%\n",
      "[TRADE] BUY confirmed at 2022-02-28 08:00:00 | close price = 432.1400\n",
      "[TRADE] SELL confirmed at 2022-02-28 13:10:00 | close price = 435.0000 | trade return = 0.56%\n",
      "[TRADE] BUY confirmed at 2022-02-28 14:05:00 | close price = 431.2100\n",
      "[TRADE] SELL confirmed at 2022-02-28 15:20:00 | close price = 433.8300 | trade return = 0.51%\n",
      "[TRADE] BUY confirmed at 2022-02-28 19:45:00 | close price = 436.0000\n",
      "[TRADE] SELL confirmed at 2022-02-28 19:45:00 | close price = 436.0000 | trade return = -0.10%\n",
      "    Day summary: trades=3, win_rate=66.7%, day_return=0.67%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-01\n",
      "     Train: 2022-01-13 â†’ 2022-02-25 (30 days)\n",
      "     Threshold days: 2022-02-28 â†’ 2022-02-28 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-13 â†’ 2022-02-25 | samples: buy=604, sell=678\n",
      "    [Thresholds] Buy=2.12%, Sell=-0.50%\n",
      "[TRADE] BUY confirmed at 2022-03-01 05:05:00 | close price = 433.3500\n",
      "[TRADE] SELL confirmed at 2022-03-01 06:30:00 | close price = 434.3100 | trade return = 0.12%\n",
      "[TRADE] BUY confirmed at 2022-03-01 15:50:00 | close price = 429.2700\n",
      "[TRADE] SELL confirmed at 2022-03-01 15:50:00 | close price = 429.2700 | trade return = -0.10%\n",
      "    Day summary: trades=2, win_rate=50.0%, day_return=-0.18%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-02\n",
      "     Train: 2022-01-14 â†’ 2022-02-28 (30 days)\n",
      "     Threshold days: 2022-03-01 â†’ 2022-03-01 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-14 â†’ 2022-02-28 | samples: buy=594, sell=674\n",
      "    [Thresholds] Buy=1.88%, Sell=2.00%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-03\n",
      "     Train: 2022-01-18 â†’ 2022-03-01 (30 days)\n",
      "     Threshold days: 2022-03-02 â†’ 2022-03-02 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-18 â†’ 2022-03-01 | samples: buy=592, sell=677\n",
      "    [Thresholds] Buy=-0.50%, Sell=2.75%\n",
      "[TRADE] BUY confirmed at 2022-03-03 05:15:00 | close price = 436.8000\n",
      "[TRADE] SELL confirmed at 2022-03-03 08:40:00 | close price = 439.4000 | trade return = 0.49%\n",
      "[TRADE] BUY confirmed at 2022-03-03 10:20:00 | close price = 437.4900\n",
      "[TRADE] SELL confirmed at 2022-03-03 19:55:00 | close price = 429.2100 | trade return = -1.99%\n",
      "    Day summary: trades=2, win_rate=50.0%, day_return=-1.70%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-04\n",
      "     Train: 2022-01-19 â†’ 2022-03-02 (30 days)\n",
      "     Threshold days: 2022-03-03 â†’ 2022-03-03 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-19 â†’ 2022-03-02 | samples: buy=571, sell=671\n",
      "    [Thresholds] Buy=2.62%, Sell=1.38%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-07\n",
      "     Train: 2022-01-20 â†’ 2022-03-03 (30 days)\n",
      "     Threshold days: 2022-03-04 â†’ 2022-03-04 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-20 â†’ 2022-03-03 | samples: buy=560, sell=676\n",
      "    [Thresholds] Buy=1.88%, Sell=1.75%\n",
      "[TRADE] BUY confirmed at 2022-03-07 04:35:00 | close price = 425.4200\n",
      "[TRADE] SELL confirmed at 2022-03-07 05:15:00 | close price = 426.2300 | trade return = 0.09%\n",
      "[TRADE] BUY confirmed at 2022-03-07 06:00:00 | close price = 424.7300\n",
      "[TRADE] SELL confirmed at 2022-03-07 09:20:00 | close price = 432.0100 | trade return = 1.61%\n",
      "[TRADE] BUY confirmed at 2022-03-07 11:55:00 | close price = 424.1700\n",
      "[TRADE] SELL confirmed at 2022-03-07 12:50:00 | close price = 423.1900 | trade return = -0.33%\n",
      "[TRADE] BUY confirmed at 2022-03-07 14:40:00 | close price = 421.8300\n",
      "[TRADE] SELL confirmed at 2022-03-07 18:30:00 | close price = 418.0100 | trade return = -1.00%\n",
      "    Day summary: trades=4, win_rate=50.0%, day_return=-0.05%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-08\n",
      "     Train: 2022-01-21 â†’ 2022-03-04 (30 days)\n",
      "     Threshold days: 2022-03-07 â†’ 2022-03-07 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-21 â†’ 2022-03-04 | samples: buy=552, sell=673\n",
      "    [Thresholds] Buy=2.88%, Sell=-0.50%\n",
      "[TRADE] BUY confirmed at 2022-03-08 14:00:00 | close price = 418.6000\n",
      "[TRADE] SELL confirmed at 2022-03-08 14:25:00 | close price = 420.8300 | trade return = 0.43%\n",
      "[TRADE] BUY confirmed at 2022-03-08 15:30:00 | close price = 417.7300\n",
      "[TRADE] SELL confirmed at 2022-03-08 18:30:00 | close price = 416.2900 | trade return = -0.44%\n",
      "    Day summary: trades=2, win_rate=50.0%, day_return=-0.21%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-09\n",
      "     Train: 2022-01-24 â†’ 2022-03-07 (30 days)\n",
      "     Threshold days: 2022-03-08 â†’ 2022-03-08 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-24 â†’ 2022-03-07 | samples: buy=551, sell=664\n",
      "    [Thresholds] Buy=1.62%, Sell=3.00%\n",
      "[TRADE] BUY confirmed at 2022-03-09 06:45:00 | close price = 422.8800\n",
      "[TRADE] SELL confirmed at 2022-03-09 14:35:00 | close price = 427.6800 | trade return = 1.03%\n",
      "    Day summary: trades=1, win_rate=100.0%, day_return=0.93%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-10\n",
      "     Train: 2022-01-25 â†’ 2022-03-08 (30 days)\n",
      "     Threshold days: 2022-03-09 â†’ 2022-03-09 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-25 â†’ 2022-03-08 | samples: buy=545, sell=690\n",
      "    [Thresholds] Buy=1.88%, Sell=2.62%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-11\n",
      "     Train: 2022-01-26 â†’ 2022-03-09 (30 days)\n",
      "     Threshold days: 2022-03-10 â†’ 2022-03-10 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-26 â†’ 2022-03-09 | samples: buy=527, sell=680\n",
      "    [Thresholds] Buy=1.50%, Sell=2.88%\n",
      "[TRADE] BUY confirmed at 2022-03-11 15:50:00 | close price = 420.4000\n",
      "[TRADE] SELL confirmed at 2022-03-11 15:55:00 | close price = 420.0800 | trade return = -0.18%\n",
      "    Day summary: trades=1, win_rate=0.0%, day_return=-0.28%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-14\n",
      "     Train: 2022-01-27 â†’ 2022-03-10 (30 days)\n",
      "     Threshold days: 2022-03-11 â†’ 2022-03-11 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-27 â†’ 2022-03-10 | samples: buy=536, sell=673\n",
      "    [Thresholds] Buy=1.62%, Sell=-0.50%\n",
      "[TRADE] BUY confirmed at 2022-03-14 04:30:00 | close price = 422.0700\n",
      "[TRADE] SELL confirmed at 2022-03-14 05:00:00 | close price = 423.2000 | trade return = 0.17%\n",
      "[TRADE] BUY confirmed at 2022-03-14 06:45:00 | close price = 423.4600\n",
      "[TRADE] SELL confirmed at 2022-03-14 08:55:00 | close price = 422.2699 | trade return = -0.38%\n",
      "[TRADE] BUY confirmed at 2022-03-14 09:35:00 | close price = 419.7400\n",
      "[TRADE] SELL confirmed at 2022-03-14 10:10:00 | close price = 422.9500 | trade return = 0.66%\n",
      "[TRADE] BUY confirmed at 2022-03-14 11:35:00 | close price = 421.6550\n",
      "[TRADE] SELL confirmed at 2022-03-14 12:40:00 | close price = 419.4900 | trade return = -0.61%\n",
      "[TRADE] BUY confirmed at 2022-03-14 12:45:00 | close price = 418.9002\n",
      "[TRADE] SELL confirmed at 2022-03-14 14:55:00 | close price = 417.1200 | trade return = -0.52%\n",
      "[TRADE] BUY confirmed at 2022-03-14 19:10:00 | close price = 417.9400\n",
      "[TRADE] SELL confirmed at 2022-03-14 19:10:00 | close price = 417.9400 | trade return = -0.10%\n",
      "    Day summary: trades=6, win_rate=33.3%, day_return=-1.38%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-15\n",
      "     Train: 2022-01-28 â†’ 2022-03-11 (30 days)\n",
      "     Threshold days: 2022-03-14 â†’ 2022-03-14 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-28 â†’ 2022-03-11 | samples: buy=528, sell=653\n",
      "    [Thresholds] Buy=2.88%, Sell=1.88%\n",
      "[TRADE] BUY confirmed at 2022-03-15 04:20:00 | close price = 415.1000\n",
      "[TRADE] SELL confirmed at 2022-03-15 15:25:00 | close price = 425.7720 | trade return = 2.47%\n",
      "    Day summary: trades=1, win_rate=100.0%, day_return=2.37%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-16\n",
      "     Train: 2022-01-31 â†’ 2022-03-14 (30 days)\n",
      "     Threshold days: 2022-03-15 â†’ 2022-03-15 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-01-31 â†’ 2022-03-14 | samples: buy=542, sell=666\n",
      "    [Thresholds] Buy=3.00%, Sell=2.25%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-17\n",
      "     Train: 2022-02-01 â†’ 2022-03-15 (30 days)\n",
      "     Threshold days: 2022-03-16 â†’ 2022-03-16 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-01 â†’ 2022-03-15 | samples: buy=536, sell=655\n",
      "    [Thresholds] Buy=1.38%, Sell=3.00%\n",
      "[TRADE] BUY confirmed at 2022-03-17 06:05:00 | close price = 432.8400\n",
      "[TRADE] SELL confirmed at 2022-03-17 19:30:00 | close price = 438.5500 | trade return = 1.22%\n",
      "    Day summary: trades=1, win_rate=100.0%, day_return=1.12%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-18\n",
      "     Train: 2022-02-02 â†’ 2022-03-16 (30 days)\n",
      "     Threshold days: 2022-03-17 â†’ 2022-03-17 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-02 â†’ 2022-03-16 | samples: buy=543, sell=647\n",
      "    [Thresholds] Buy=0.62%, Sell=2.12%\n",
      "[TRADE] BUY confirmed at 2022-03-18 04:30:00 | close price = 437.1100\n",
      "[TRADE] SELL confirmed at 2022-03-18 19:55:00 | close price = 445.4900 | trade return = 1.82%\n",
      "    Day summary: trades=1, win_rate=100.0%, day_return=1.71%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-21\n",
      "     Train: 2022-02-03 â†’ 2022-03-17 (30 days)\n",
      "     Threshold days: 2022-03-18 â†’ 2022-03-18 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-03 â†’ 2022-03-17 | samples: buy=553, sell=641\n",
      "    [Thresholds] Buy=1.25%, Sell=1.50%\n",
      "[TRADE] BUY confirmed at 2022-03-21 05:05:00 | close price = 443.6500\n",
      "[TRADE] SELL confirmed at 2022-03-21 10:50:00 | close price = 444.5100 | trade return = 0.09%\n",
      "[TRADE] BUY confirmed at 2022-03-21 13:00:00 | close price = 441.7800\n",
      "[TRADE] SELL confirmed at 2022-03-21 14:00:00 | close price = 442.2400 | trade return = 0.00%\n",
      "    Day summary: trades=2, win_rate=100.0%, day_return=-0.10%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-22\n",
      "     Train: 2022-02-04 â†’ 2022-03-18 (30 days)\n",
      "     Threshold days: 2022-03-21 â†’ 2022-03-21 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-04 â†’ 2022-03-18 | samples: buy=536, sell=656\n",
      "    [Thresholds] Buy=1.50%, Sell=2.38%\n",
      "[TRADE] BUY confirmed at 2022-03-22 12:30:00 | close price = 448.2100\n",
      "[TRADE] SELL confirmed at 2022-03-22 15:50:00 | close price = 449.1900 | trade return = 0.12%\n",
      "    Day summary: trades=1, win_rate=100.0%, day_return=0.02%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-23\n",
      "     Train: 2022-02-07 â†’ 2022-03-21 (30 days)\n",
      "     Threshold days: 2022-03-22 â†’ 2022-03-22 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-07 â†’ 2022-03-21 | samples: buy=554, sell=659\n",
      "    [Thresholds] Buy=1.88%, Sell=2.12%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-24\n",
      "     Train: 2022-02-08 â†’ 2022-03-22 (30 days)\n",
      "     Threshold days: 2022-03-23 â†’ 2022-03-23 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-08 â†’ 2022-03-22 | samples: buy=553, sell=647\n",
      "    [Thresholds] Buy=-0.50%, Sell=1.38%\n",
      "[TRADE] BUY confirmed at 2022-03-24 05:55:00 | close price = 446.4000\n",
      "[TRADE] SELL confirmed at 2022-03-24 12:55:00 | close price = 447.7502 | trade return = 0.20%\n",
      "[TRADE] BUY confirmed at 2022-03-24 14:45:00 | close price = 447.6400\n",
      "[TRADE] SELL confirmed at 2022-03-24 15:15:00 | close price = 449.0089 | trade return = 0.21%\n",
      "[TRADE] BUY confirmed at 2022-03-24 19:10:00 | close price = 450.0400\n",
      "[TRADE] SELL confirmed at 2022-03-24 19:10:00 | close price = 450.0400 | trade return = -0.10%\n",
      "    Day summary: trades=3, win_rate=66.7%, day_return=0.01%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-25\n",
      "     Train: 2022-02-09 â†’ 2022-03-23 (30 days)\n",
      "     Threshold days: 2022-03-24 â†’ 2022-03-24 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-09 â†’ 2022-03-23 | samples: buy=562, sell=624\n",
      "    [Thresholds] Buy=1.12%, Sell=2.75%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-28\n",
      "     Train: 2022-02-10 â†’ 2022-03-24 (30 days)\n",
      "     Threshold days: 2022-03-25 â†’ 2022-03-25 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-10 â†’ 2022-03-24 | samples: buy=575, sell=620\n",
      "    [Thresholds] Buy=-0.50%, Sell=2.75%\n",
      "[TRADE] BUY confirmed at 2022-03-28 04:05:00 | close price = 451.4300\n",
      "[TRADE] SELL confirmed at 2022-03-28 04:40:00 | close price = 452.1100 | trade return = 0.05%\n",
      "[TRADE] BUY confirmed at 2022-03-28 05:20:00 | close price = 452.0400\n",
      "[TRADE] SELL confirmed at 2022-03-28 06:15:00 | close price = 452.6800 | trade return = 0.04%\n",
      "[TRADE] BUY confirmed at 2022-03-28 11:25:00 | close price = 452.4000\n",
      "[TRADE] SELL confirmed at 2022-03-28 12:40:00 | close price = 451.3100 | trade return = -0.34%\n",
      "    Day summary: trades=3, win_rate=66.7%, day_return=-0.55%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-29\n",
      "     Train: 2022-02-11 â†’ 2022-03-25 (30 days)\n",
      "     Threshold days: 2022-03-28 â†’ 2022-03-28 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-11 â†’ 2022-03-25 | samples: buy=557, sell=626\n",
      "    [Thresholds] Buy=1.38%, Sell=2.75%\n",
      "    Day summary: trades=0, win_rate=0.0%, day_return=0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "[WF] Test day: 2022-03-30\n",
      "     Train: 2022-02-14 â†’ 2022-03-28 (30 days)\n",
      "     Threshold days: 2022-03-29 â†’ 2022-03-29 (1 days)\n",
      "[MODEL] XGBoost models trained | train window: 2022-02-14 â†’ 2022-03-28 | samples: buy=554, sell=644\n",
      "    [Thresholds] Buy=1.75%, Sell=0.75%\n",
      "[TRADE] BUY confirmed at 2022-03-30 04:50:00 | close price = 459.6400\n",
      "[TRADE] SELL confirmed at 2022-03-30 15:20:00 | close price = 456.5700 | trade return = -0.77%\n",
      "    Day summary: trades=1, win_rate=0.0%, day_return=-0.87%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 9. Example call (same style as before)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Example usage in your notebook:\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m results = \u001b[43mrun_realtime_chan_xgb_trading_walkforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDataAPI/data/SPY_5M.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSPY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2022-01-01\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2022-03-31\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKL_TYPE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mK_5M\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchan_window_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_days_for_model\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# param\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreshold_days_for_selection\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# param\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_train_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_valid_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_capital\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransaction_fee_pct\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 0.1% per side\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./output/chan_xgb_streaming\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m trades_df = results[\u001b[33m\"\u001b[39m\u001b[33mtrades_df\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     27\u001b[39m daily_df  = results[\u001b[33m\"\u001b[39m\u001b[33mdaily_results_df\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 788\u001b[39m, in \u001b[36mrun_realtime_chan_xgb_trading_walkforward\u001b[39m\u001b[34m(csv_path, code, start_time, end_time, lv, chan_window_size, train_days_for_model, threshold_days_for_selection, min_train_samples, min_valid_samples, initial_capital, position_size, transaction_fee_pct, output_dir, plot_results, verbose)\u001b[39m\n\u001b[32m    785\u001b[39m daily_results_df = pd.DataFrame(daily_results).sort_values(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    787\u001b[39m \u001b[38;5;66;03m# 5) Buy & Hold benchmark\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m bh_df = \u001b[43mcalc_buy_hold_daily\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    789\u001b[39m bh_map = bh_df.set_index(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mcum_return_pct\u001b[39m\u001b[33m'\u001b[39m].to_dict()\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# Align B&H to strategy days\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 431\u001b[39m, in \u001b[36mcalc_buy_hold_daily\u001b[39m\u001b[34m(csv_path, start_time, end_time)\u001b[39m\n\u001b[32m    429\u001b[39m mask = (raw[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] >= pd.to_datetime(start_time)) & (raw[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] <= pd.to_datetime(end_time))\n\u001b[32m    430\u001b[39m raw = raw[mask].copy()\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m raw[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mraw\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m.date\n\u001b[32m    433\u001b[39m daily = raw.groupby(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m)[close_col].agg([\u001b[33m'\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    434\u001b[39m daily.rename(columns={\u001b[33m'\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mopen\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TonyTang\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:6318\u001b[39m, in \u001b[36mNDFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   6312\u001b[39m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_names_set\n\u001b[32m   6313\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metadata\n\u001b[32m   6314\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessors\n\u001b[32m   6315\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m ):\n\u001b[32m   6317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TonyTang\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[39m, in \u001b[36mCachedAccessor.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessor\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m accessor_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m._name, accessor_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TonyTang\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[39m, in \u001b[36mCombinedDatetimelikeProperties.__new__\u001b[39m\u001b[34m(cls, data)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data.dtype, PeriodDtype):\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9. Example call (same style as before)\n",
    "# ============================================================\n",
    "\n",
    "# Example usage in your notebook:\n",
    "#\n",
    "results = run_realtime_chan_xgb_trading_walkforward(\n",
    "    csv_path=\"DataAPI/data/SPY_5M.csv\",\n",
    "    code=\"SPY\",\n",
    "    start_time=\"2022-01-01\",\n",
    "    end_time=\"2022-03-31\",\n",
    "    lv=KL_TYPE.K_5M,\n",
    "    chan_window_size=500,\n",
    "    train_days_for_model=30,          # param\n",
    "    threshold_days_for_selection=1,   # param\n",
    "    min_train_samples=100,\n",
    "    min_valid_samples=20,\n",
    "    initial_capital=100_000,\n",
    "    position_size=1.0,\n",
    "    transaction_fee_pct=0.001,        # 0.1% per side\n",
    "    output_dir=\"./output/chan_xgb_streaming\",\n",
    "    plot_results=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "trades_df = results[\"trades_df\"]\n",
    "daily_df  = results[\"daily_results_df\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
